{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0394574",
   "metadata": {},
   "source": [
    "# Fictional Characters Reddit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab6ec62",
   "metadata": {},
   "source": [
    "Most of the Reddit data was obtained through the University and is in .pickle format. A small subset of the data was scraped directly from old.reddit.com in cases where the data needed was limited to only specific threads (for example, data pertaining to \"Catcher in the Rye\" on the r/literature or r/books subreddits).\n",
    "\n",
    "First, I will proceed with loading, cleaning, and preprocessing the .pickle data, as this is the format of most of the data.\n",
    "\n",
    "I will use the format below for each set of data pertaining to the different fictional works. I will replace breakingbad_data with a new variable for each different set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f50f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = r'C:\\Users\\josie\\Downloads\\Josie\\BreakingBad' #Breaking Bad as an example\n",
    "\n",
    "# List all the pickle files that the folder contains\n",
    "pickle_files = [file for file in os.listdir(folder_path) if file.endswith('.pickle')]\n",
    "\n",
    "# Initialize empty list to store loaded data\n",
    "data = {}\n",
    "\n",
    "# Loop through each pickle file and load its contents\n",
    "for file_name in pickle_files:\n",
    "    with open(os.path.join(folder_path, file_name), 'rb') as f:\n",
    "        data[file_name] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dadc78",
   "metadata": {},
   "source": [
    "# Cleaning and Preprocessing all Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48157118",
   "metadata": {},
   "source": [
    "## \"r/HarryPotter\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031bc604",
   "metadata": {},
   "source": [
    "### Step 1: Upload Data, Check and Inspect Contents, Create Merged Dataframe\n",
    "\n",
    "All of the Harry Potter Reddit Data is located in the folder \"harrypotter\" within the \"Reddit\" folder that contains all the other Reddit data.\n",
    "\n",
    "First, we need to load it into our Python terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4b17b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the folder containing the Harry Potter pickle files\n",
    "folder_path = r'C:\\Users\\josie\\OneDrive\\Desktop\\Reddit\\harrypotter'\n",
    "\n",
    "# List all the pickle files that the folder contains\n",
    "pickle_files = [file for file in os.listdir(folder_path) if file.endswith('.pickle')]\n",
    "\n",
    "# Initialize empty dictionary to store loaded data\n",
    "harry_potter_data = {}\n",
    "\n",
    "# Load each pickle file and store its contents in the dictionary\n",
    "for file_name in pickle_files:\n",
    "    with open(os.path.join(folder_path, file_name), 'rb') as f:\n",
    "        harry_potter_data[file_name] = pickle.load(f)\n",
    "\n",
    "# Now I have all the loaded Harry Potter data stored in the dictionary 'harry_potter_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa24a6",
   "metadata": {},
   "source": [
    "I will now check the data to see its structure and inspect its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "54faa1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: subreddit_HarryPotterBooks_RC_2014-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2014-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2014-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2014-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2014-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2014-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2014-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2014-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2014-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2014-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2014-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2014-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2015-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2015-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2015-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2015-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2015-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2015-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2015-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2015-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2015-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2015-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2015-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2016-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2016-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2016-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2016-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2016-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2016-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2016-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2016-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2016-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2016-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2016-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2016-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2017-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2017-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2017-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2017-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2017-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2017-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2017-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2017-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2017-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2017-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2017-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2017-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2018-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2018-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2018-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2018-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2018-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2018-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2018-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2018-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2018-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2018-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2018-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2018-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RC_2020-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2018-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2018-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2018-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2018-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2018-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2018-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2018-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2018-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2018-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2018-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2018-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2018-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2019-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2019-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2019-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2019-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2019-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2019-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2019-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2019-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2019-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2019-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2019-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2019-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2020-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2020-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2020-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2020-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2020-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2020-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2020-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2020-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2020-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2020-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2020-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2020-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2021-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2021-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2021-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2021-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2021-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2021-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2021-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2021-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2021-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2021-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2021-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2021-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2022-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2022-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2022-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2022-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2022-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2022-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2022-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2022-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2022-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2022-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2022-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_HarryPotterBooks_RS_2022-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2009-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2010-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2010-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2010-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2010-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2010-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2010-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2010-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2010-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2011-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2011-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2011-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2011-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2011-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2011-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2011-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2011-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2011-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2011-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2011-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2011-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2012-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2012-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2012-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2012-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2012-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2012-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2012-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2012-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2012-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2012-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2012-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2012-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2013-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2013-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2013-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2013-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2013-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2013-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2013-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2013-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2013-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2013-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2013-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2013-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2014-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2014-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2014-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2014-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2014-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2014-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2014-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2014-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2014-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2014-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2014-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2014-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2015-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2015-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2015-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2015-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2015-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2015-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2015-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2015-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2015-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2015-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2015-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2015-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2016-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2016-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2016-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2016-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2016-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2016-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2016-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2016-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2016-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2016-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2016-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2016-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2017-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2017-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2017-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2017-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2017-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2017-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2017-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2017-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2017-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2017-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2017-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2017-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2018-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2018-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2018-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2018-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2018-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2018-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2018-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2018-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2018-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2018-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2018-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2018-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RC_2020-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2008-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2009-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2009-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2009-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2009-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2010-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2010-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2010-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2010-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2010-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2010-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2010-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2010-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2010-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2010-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2018-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2018-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2018-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2018-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2018-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2018-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2018-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2018-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2018-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2018-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2018-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2018-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2019-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2019-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2019-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2019-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2019-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2019-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2019-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2019-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2019-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2019-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2019-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2019-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2020-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2020-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2020-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2020-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2020-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2020-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2020-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2020-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2020-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2020-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2020-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2020-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2021-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2021-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2021-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2021-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2021-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2021-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2021-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2021-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2021-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2021-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2021-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2021-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2022-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2022-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2022-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2022-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2022-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2022-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2022-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2022-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2022-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2022-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2022-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_harrypotter_RS_2022-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each pickle file and inspect its contents\n",
    "for file_name, data in harry_potter_data.items():\n",
    "    print(f\"File: {file_name}\")\n",
    "    print(f\"Data type: {type(data)}\")\n",
    "    print(f\"Keys: {data.keys()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be9fbc",
   "metadata": {},
   "source": [
    "The dataset contains files belonging to the subreddits r/HarryPotter and r/HarryPotterBooks.\n",
    "\n",
    "We are interested in keeping these analyses separate, so we will first explore the r/HarryPotter data alone.\n",
    "\n",
    "RS refers to 'Reddit Submissions' and RC refers to 'Reddit Comments'. These files will contain differently structured dataframes, so I will first create 2 different dataframes concatenating the RS and RC data separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "24c12f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize empty dictionaries to store RS (Reddit submissions) and RC (Reddit comments) DataFrames\n",
    "rs_data = {}\n",
    "rc_data = {}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a Reddit submission file\n",
    "    if file_name.startswith(\"subreddit_harrypotter_RS\"):\n",
    "        # Load the RS DataFrame and store it in the dictionary with the corresponding date as the key\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rs_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "    \n",
    "    # Check if the file is a Reddit comment file\n",
    "    elif file_name.startswith(\"subreddit_harrypotter_RC\"):\n",
    "        # Load the RC DataFrame and store it in the dictionary with the corresponding date as the key\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rc_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "\n",
    "# Concatenate all the RS DataFrames into a single DataFrame\n",
    "harry_potter_submissions = pd.concat(rs_data.values(), ignore_index=True)\n",
    "\n",
    "# Concatenate all the RC DataFrames into a single DataFrame\n",
    "harry_potter_comments = pd.concat(rc_data.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87afc8bf",
   "metadata": {},
   "source": [
    "The 'id' column in harry_potter_submissions (originally RS) contains values like '91mvt' while the link_id and parent_id contain values like 't3_91mvt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "367eb41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values in 'link_id' column start with 't3_': True\n"
     ]
    }
   ],
   "source": [
    "# Check if all values in 'link_id' column start with 't3_'\n",
    "all_values_start_with_t3 = harry_potter_comments['link_id'].str.startswith('t3_').all()\n",
    "\n",
    "print(\"All values in 'link_id' column start with 't3_':\", all_values_start_with_t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d7cce8",
   "metadata": {},
   "source": [
    "If we remove the 't3_' prefix that appears to be consistent so that I can merge the two dataframes on the matching column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "02d5b85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    link_id cleaned_link_id\n",
      "0  t3_91mvt           91mvt\n",
      "1  t3_bzfhl           bzfhl\n",
      "2  t3_ai9xg           ai9xg\n",
      "3  t3_bzfhl           bzfhl\n",
      "4  t3_ckp0j           ckp0j\n",
      "  id_comment    author_comment   link_id parent_id subreddit_comment  \\\n",
      "0    c0b57bl         [deleted]  t3_91mvt  t3_91mvt       harrypotter   \n",
      "1    c0pd55y         NitsujTPU  t3_bzfhl  t3_bzfhl       harrypotter   \n",
      "2    c0rmz31  theartfulrambler  t3_bzfhl  t3_bzfhl       harrypotter   \n",
      "3    c0rjt2h   FruitySnackLove  t3_ai9xg  t3_ai9xg       harrypotter   \n",
      "4    c0tgbmr     WordsVerbatim  t3_ckp0j  t3_ckp0j       harrypotter   \n",
      "\n",
      "                                                body cleaned_link_id  \\\n",
      "0                                          [deleted]           91mvt   \n",
      "1  These quotes aren't very good, no offense.\\n\\n...           bzfhl   \n",
      "2      Any time Ron says 'bloody' it makes me happy.           bzfhl   \n",
      "3                                   i will try this!           ai9xg   \n",
      "4  Agreed. \\n\\nSo, was it not fucking awesome? \\n...           ckp0j   \n",
      "\n",
      "  id_submission author_submission subreddit_submission  \\\n",
      "0         91mvt         [deleted]          harrypotter   \n",
      "1         bzfhl         neiltracy          harrypotter   \n",
      "2         bzfhl         neiltracy          harrypotter   \n",
      "3         ai9xg          hpgeek42          harrypotter   \n",
      "4         ckp0j         snatchula          harrypotter   \n",
      "\n",
      "                                               title   selftext  \n",
      "0  I just watched Harry Potter and the Half Blood...  [deleted]  \n",
      "1                     Best Harry Potter Movie Quotes             \n",
      "2                     Best Harry Potter Movie Quotes             \n",
      "3                           Butterbeer - Done Proper             \n",
      "4                  NEW HP TRAILER!! Suck it Twilight             \n"
     ]
    }
   ],
   "source": [
    "# Remove the 't3_' prefix from every row in the link_id column\n",
    "harry_potter_comments['cleaned_link_id'] = harry_potter_comments['link_id'].str.replace('t3_', '', regex=False)\n",
    "\n",
    "# Display the first few rows to verify the prefix has been removed\n",
    "print(harry_potter_comments[['link_id', 'cleaned_link_id']].head())\n",
    "\n",
    "# Merge the DataFrames using the cleaned_link_id column and id column\n",
    "harrypotter_df = pd.merge(harry_potter_comments, harry_potter_submissions, left_on='cleaned_link_id', right_on='id', how='inner', suffixes=('_comment', '_submission'))\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(harrypotter_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b6d69",
   "metadata": {},
   "source": [
    "The new merged dataframe, harrypotter_df, contains some redundant columns that are no longer needed: cleaned_link_id appears twice and is not needed in light of the id_submission that connects the original submission to its corresponding comments, so we can drop it and visualize the new results.\n",
    "\n",
    "link_id and parent_id are also unnecessary now, so I will also remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "51c809b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id_comment    author_comment subreddit_comment  \\\n",
      "0    c0b57bl         [deleted]       harrypotter   \n",
      "1    c0pd55y         NitsujTPU       harrypotter   \n",
      "2    c0rmz31  theartfulrambler       harrypotter   \n",
      "3    c0rjt2h   FruitySnackLove       harrypotter   \n",
      "4    c0tgbmr     WordsVerbatim       harrypotter   \n",
      "\n",
      "                                                body id_submission  \\\n",
      "0                                          [deleted]         91mvt   \n",
      "1  These quotes aren't very good, no offense.\\n\\n...         bzfhl   \n",
      "2      Any time Ron says 'bloody' it makes me happy.         bzfhl   \n",
      "3                                   i will try this!         ai9xg   \n",
      "4  Agreed. \\n\\nSo, was it not fucking awesome? \\n...         ckp0j   \n",
      "\n",
      "  author_submission subreddit_submission  \\\n",
      "0         [deleted]          harrypotter   \n",
      "1         neiltracy          harrypotter   \n",
      "2         neiltracy          harrypotter   \n",
      "3          hpgeek42          harrypotter   \n",
      "4         snatchula          harrypotter   \n",
      "\n",
      "                                               title   selftext  \n",
      "0  I just watched Harry Potter and the Half Blood...  [deleted]  \n",
      "1                     Best Harry Potter Movie Quotes             \n",
      "2                     Best Harry Potter Movie Quotes             \n",
      "3                           Butterbeer - Done Proper             \n",
      "4                  NEW HP TRAILER!! Suck it Twilight             \n"
     ]
    }
   ],
   "source": [
    "#'cleaned_link_id' appears twice in the DataFrame\n",
    "harrypotter_df.drop(labels=['cleaned_link_id'], axis=1, inplace=True)\n",
    "harrypotter_df.drop(columns=['link_id', 'parent_id'], inplace=True)\n",
    "\n",
    "print(harrypotter_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d699879",
   "metadata": {},
   "source": [
    "### Cleaning and Preprocessing HP data\n",
    "\n",
    "Now that we've merged our dataframe and included only the relevant columns, let's proceed with our cleaning and preprocessing steps.\n",
    "\n",
    "First, let's ensure that we remove any rows with the value '[deleted]' in the 'body' column. These consist of comments that have been fully deleted by the Reddit user or admin(s) and contain no content to inspect, and are therefore useless. '[deleted]' in the 'selftext', 'author_submission', or 'author_comment' is not necessary to filter out, as there may still be corresponding comments. While we may not be able to attribute them, we are still able to use their contents for our analysis as Reddit is a public forum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1c99a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with '[deleted]' in the 'body' column\n",
    "harrypotter_df = harrypotter_df[harrypotter_df['body'] != '[deleted]']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf1753",
   "metadata": {},
   "source": [
    "Now we can proceed with the lowercasing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "864a846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase 'body' column\n",
    "harrypotter_df['body'] = harrypotter_df['body'].str.lower()\n",
    "\n",
    "# Lowercase 'selftext' column\n",
    "harrypotter_df['selftext'] = harrypotter_df['selftext'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79035c2e",
   "metadata": {},
   "source": [
    "Now with removing the punctuation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c1e8bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Define a function to remove punctuation from a string\n",
    "def remove_punctuation(text):\n",
    "    # Get the predefined set of punctuation characters\n",
    "    punctuation_set = set(string.punctuation)\n",
    "    # Use ''.join() to remove punctuation\n",
    "    return ''.join(char for char in text if char not in punctuation_set)\n",
    "\n",
    "# Remove punctuation from the relevant columns\n",
    "text_columns = ['body', 'selftext']\n",
    "harrypotter_df[text_columns] = harrypotter_df[text_columns].applymap(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8414bb9",
   "metadata": {},
   "source": [
    "\\n\\n is used to denote paragraph breaks or new sections of text. We can proceed with removing those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cc58e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '\\n\\n' with a space in the 'body' and 'selftext' columns\n",
    "harrypotter_df['body'] = harrypotter_df['body'].str.replace('\\n\\n', ' ')\n",
    "harrypotter_df['selftext'] = harrypotter_df['selftext'].str.replace('\\n\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cc47e3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to C:\\Users\\josie\\Downloads\\REDDIT_HP_DATA_CLEANED.txt\n"
     ]
    }
   ],
   "source": [
    "cleaned_file_path = r'C:\\Users\\josie\\Downloads\\REDDIT_HP_DATA_CLEANED.txt'\n",
    "harrypotter_df.to_csv(cleaned_file_path, index=False, sep='\\t')\n",
    "\n",
    "print(f\"Cleaned data saved to {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83350045",
   "metadata": {},
   "source": [
    "## Now save all relevant columns and groupings accordingly as .txt files before tokenizing for analysis in Voyant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b4a1e",
   "metadata": {},
   "source": [
    "Now, we can move ahead with tokenizing, starting with the 'body' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b0b89712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1         [these, quotes, arent, very, good, no, offense...\n",
      "2         [any, time, ron, says, bloody, it, makes, me, ...\n",
      "3                                      [i, will, try, this]\n",
      "4           [agreed, so, was, it, not, fucking, awesome, d]\n",
      "5         [im, so, excited, i, keep, thinking, about, wh...\n",
      "                                ...                        \n",
      "635399    [from, memory, the, only, other, thing, i, can...\n",
      "635400    [nah, i, think, if, she, can, watch, gof, she,...\n",
      "635401    [i, also, thought, about, what, i, am, going, ...\n",
      "635402    [thanks, for, the, advice, man, yeah, i, , m,...\n",
      "635403                  [yes, he, does, an, excellent, job]\n",
      "Name: body, Length: 615681, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize the 'body' column\n",
    "harrypotter_df['body'] = harrypotter_df['body'].apply(word_tokenize)\n",
    "\n",
    "# Print the updated 'body' column\n",
    "print(harrypotter_df['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdad5da",
   "metadata": {},
   "source": [
    "Now, the 'selftext' column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "406d3e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "harrypotter_df['selftext'] = harrypotter_df['selftext'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa850bd2",
   "metadata": {},
   "source": [
    "Finally, let's remove the stopwords, but only from the 'body' and 'selftext' columns. We want to keep the titles intact because it could be difficult to discern the prompt without the original language and formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "275e66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Define the stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords from the tokenized 'body' column\n",
    "harrypotter_df['body'] = harrypotter_df['body'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
    "\n",
    "# Remove stopwords from the tokenized 'selftext' column\n",
    "harrypotter_df['selftext'] = harrypotter_df['selftext'].apply(lambda x: [word for word in x if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761f34b6",
   "metadata": {},
   "source": [
    "For our analyses, we are not interested in lemmatizing words as we want to pay attention to verb tenses.\n",
    "\n",
    "Now that all the cleaning and preprocessing steps have been executed, let's run a check to ensure everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "841ca0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_comment</th>\n",
       "      <th>author_comment</th>\n",
       "      <th>subreddit_comment</th>\n",
       "      <th>body</th>\n",
       "      <th>id_submission</th>\n",
       "      <th>author_submission</th>\n",
       "      <th>subreddit_submission</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c0pd55y</td>\n",
       "      <td>NitsujTPU</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>[quotes, arent, good, offense, funny, part, sh...</td>\n",
       "      <td>bzfhl</td>\n",
       "      <td>neiltracy</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>Best Harry Potter Movie Quotes</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0rmz31</td>\n",
       "      <td>theartfulrambler</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>[time, ron, says, bloody, makes, happy]</td>\n",
       "      <td>bzfhl</td>\n",
       "      <td>neiltracy</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>Best Harry Potter Movie Quotes</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0rjt2h</td>\n",
       "      <td>FruitySnackLove</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>[try]</td>\n",
       "      <td>ai9xg</td>\n",
       "      <td>hpgeek42</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>Butterbeer - Done Proper</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c0tgbmr</td>\n",
       "      <td>WordsVerbatim</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>[agreed, fucking, awesome]</td>\n",
       "      <td>ckp0j</td>\n",
       "      <td>snatchula</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>NEW HP TRAILER!! Suck it Twilight</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c0tjj7l</td>\n",
       "      <td>snatchula</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>[im, excited, keep, thinking, going, stop, fir...</td>\n",
       "      <td>ckp0j</td>\n",
       "      <td>snatchula</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>NEW HP TRAILER!! Suck it Twilight</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635399</th>\n",
       "      <td>fg4z5tb</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>[memory, thing, think, might, scary, child, me...</td>\n",
       "      <td>ewwiam</td>\n",
       "      <td>bitchdantkillmyvibe</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>How scary is the Goblet of Fire movie?</td>\n",
       "      <td>[hey, eight, year, old, daughter, massive, pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635400</th>\n",
       "      <td>fg4zeve</td>\n",
       "      <td>enfanthorrible</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>[nah, think, watch, gof, also, watch, ootp, hb...</td>\n",
       "      <td>ewwiam</td>\n",
       "      <td>bitchdantkillmyvibe</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>How scary is the Goblet of Fire movie?</td>\n",
       "      <td>[hey, eight, year, old, daughter, massive, pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635401</th>\n",
       "      <td>fg4zmzc</td>\n",
       "      <td>enfanthorrible</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>[also, thought, going, kids, future, thought, ...</td>\n",
       "      <td>ewwiam</td>\n",
       "      <td>bitchdantkillmyvibe</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>How scary is the Goblet of Fire movie?</td>\n",
       "      <td>[hey, eight, year, old, daughter, massive, pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635402</th>\n",
       "      <td>fg4zx8y</td>\n",
       "      <td>bitchdantkillmyvibe</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>[thanks, advice, man, yeah, , hoping, keep, b...</td>\n",
       "      <td>ewwiam</td>\n",
       "      <td>bitchdantkillmyvibe</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>How scary is the Goblet of Fire movie?</td>\n",
       "      <td>[hey, eight, year, old, daughter, massive, pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635403</th>\n",
       "      <td>fg4xzet</td>\n",
       "      <td>floggingmurphies</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>[yes, excellent, job]</td>\n",
       "      <td>ewx235</td>\n",
       "      <td>Filmfan345</td>\n",
       "      <td>harrypotter</td>\n",
       "      <td>Is Jim Dale worth listening to?</td>\n",
       "      <td>[, thinking, listening, harry, potter, audiob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615681 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_comment       author_comment subreddit_comment  \\\n",
       "1         c0pd55y            NitsujTPU       harrypotter   \n",
       "2         c0rmz31     theartfulrambler       harrypotter   \n",
       "3         c0rjt2h      FruitySnackLove       harrypotter   \n",
       "4         c0tgbmr        WordsVerbatim       harrypotter   \n",
       "5         c0tjj7l            snatchula       harrypotter   \n",
       "...           ...                  ...               ...   \n",
       "635399    fg4z5tb            [deleted]       harrypotter   \n",
       "635400    fg4zeve       enfanthorrible       harrypotter   \n",
       "635401    fg4zmzc       enfanthorrible       harrypotter   \n",
       "635402    fg4zx8y  bitchdantkillmyvibe       harrypotter   \n",
       "635403    fg4xzet     floggingmurphies       harrypotter   \n",
       "\n",
       "                                                     body id_submission  \\\n",
       "1       [quotes, arent, good, offense, funny, part, sh...         bzfhl   \n",
       "2                 [time, ron, says, bloody, makes, happy]         bzfhl   \n",
       "3                                                   [try]         ai9xg   \n",
       "4                              [agreed, fucking, awesome]         ckp0j   \n",
       "5       [im, excited, keep, thinking, going, stop, fir...         ckp0j   \n",
       "...                                                   ...           ...   \n",
       "635399  [memory, thing, think, might, scary, child, me...        ewwiam   \n",
       "635400  [nah, think, watch, gof, also, watch, ootp, hb...        ewwiam   \n",
       "635401  [also, thought, going, kids, future, thought, ...        ewwiam   \n",
       "635402  [thanks, advice, man, yeah, , hoping, keep, b...        ewwiam   \n",
       "635403                              [yes, excellent, job]        ewx235   \n",
       "\n",
       "          author_submission subreddit_submission  \\\n",
       "1                 neiltracy          harrypotter   \n",
       "2                 neiltracy          harrypotter   \n",
       "3                  hpgeek42          harrypotter   \n",
       "4                 snatchula          harrypotter   \n",
       "5                 snatchula          harrypotter   \n",
       "...                     ...                  ...   \n",
       "635399  bitchdantkillmyvibe          harrypotter   \n",
       "635400  bitchdantkillmyvibe          harrypotter   \n",
       "635401  bitchdantkillmyvibe          harrypotter   \n",
       "635402  bitchdantkillmyvibe          harrypotter   \n",
       "635403           Filmfan345          harrypotter   \n",
       "\n",
       "                                         title  \\\n",
       "1               Best Harry Potter Movie Quotes   \n",
       "2               Best Harry Potter Movie Quotes   \n",
       "3                     Butterbeer - Done Proper   \n",
       "4            NEW HP TRAILER!! Suck it Twilight   \n",
       "5            NEW HP TRAILER!! Suck it Twilight   \n",
       "...                                        ...   \n",
       "635399  How scary is the Goblet of Fire movie?   \n",
       "635400  How scary is the Goblet of Fire movie?   \n",
       "635401  How scary is the Goblet of Fire movie?   \n",
       "635402  How scary is the Goblet of Fire movie?   \n",
       "635403         Is Jim Dale worth listening to?   \n",
       "\n",
       "                                                 selftext  \n",
       "1                                                      []  \n",
       "2                                                      []  \n",
       "3                                                      []  \n",
       "4                                                      []  \n",
       "5                                                      []  \n",
       "...                                                   ...  \n",
       "635399  [hey, eight, year, old, daughter, massive, pot...  \n",
       "635400  [hey, eight, year, old, daughter, massive, pot...  \n",
       "635401  [hey, eight, year, old, daughter, massive, pot...  \n",
       "635402  [hey, eight, year, old, daughter, massive, pot...  \n",
       "635403  [, thinking, listening, harry, potter, audiob...  \n",
       "\n",
       "[615681 rows x 9 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harrypotter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09bfb9d",
   "metadata": {},
   "source": [
    "## \"r/HarryPotterBooks\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b873ece",
   "metadata": {},
   "source": [
    "Let's repeat the process for the r/HarryPotterBooks data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "90bb5ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id           author    link_id   parent_id         subreddit  \\\n",
      "0  ceff2fg        [deleted]  t3_1tcbbk   t3_1tcbbk  HarryPotterBooks   \n",
      "1  cegbo9j          GameOfT  t3_1tcbbk   t3_1tcbbk  HarryPotterBooks   \n",
      "2  cejfxkq            Rjr18  t3_1ulye4   t3_1ulye4  HarryPotterBooks   \n",
      "3  cejgivj   MilkIsMyPotion  t3_1ulye4   t3_1ulye4  HarryPotterBooks   \n",
      "4  cejkfmq  GaslightProphet  t3_1sp5h8  t1_ce040as  HarryPotterBooks   \n",
      "\n",
      "                                                body  \n",
      "0                                          [deleted]  \n",
      "1  There are a lot of twists and turns throughout...  \n",
      "2  Easily the Half-Blood Prince. I think it has t...  \n",
      "3  Its GoF. Not only because it was my first Harr...  \n",
      "4         Didnt the movies pronounce it Her-My-Knee?  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the folder containing the pickle files\n",
    "folder_path = r'C:\\Users\\josie\\OneDrive\\Desktop\\Reddit\\harrypotter'\n",
    "\n",
    "# Load a sample pickle file\n",
    "sample_file = [file for file in os.listdir(folder_path) if file.startswith('subreddit_HarryPotterBooks_RC')][0]\n",
    "\n",
    "# Load the sample file to inspect\n",
    "sample_df = pd.read_pickle(os.path.join(folder_path, sample_file))\n",
    "\n",
    "# Display the first few rows of the sample DataFrame\n",
    "print(sample_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6e9885f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries to store RS (Reddit submissions) and RC (Reddit comments) DataFrames\n",
    "rs_data = {}\n",
    "rc_data = {}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a Reddit submission file\n",
    "    if file_name.startswith(\"subreddit_HarryPotterBooks_RS\"):\n",
    "        # Load the RS DataFrame and store it in the dictionary with the corresponding date as the key\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rs_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "    \n",
    "    # Check if the file is a Reddit comment file\n",
    "    elif file_name.startswith(\"subreddit_HarryPotterBooks_RC\"):\n",
    "        # Load the RC DataFrame and store it in the dictionary with the corresponding date as the key\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rc_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "\n",
    "# Concatenate all the RS DataFrames into a single DataFrame\n",
    "harry_potter_books_submissions = pd.concat(rs_data.values(), ignore_index=True)\n",
    "\n",
    "# Concatenate all the RC DataFrames into a single DataFrame\n",
    "harry_potter_books_comments = pd.concat(rc_data.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "18fdb07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id              author         subreddit  \\\n",
      "0     7ndcao         stiinabiina  HarryPotterBooks   \n",
      "1     7nkkre           Dillonk12  HarryPotterBooks   \n",
      "2     7nnux9           [deleted]  HarryPotterBooks   \n",
      "3     7ntkop              tebz07  HarryPotterBooks   \n",
      "4     7nttwp          AluminiaHz  HarryPotterBooks   \n",
      "...      ...                 ...               ...   \n",
      "6306  zydekn            stlshlee  HarryPotterBooks   \n",
      "6307  zyihxq            ivaninge  HarryPotterBooks   \n",
      "6308  zym9vf  DingoAgreeable9141  HarryPotterBooks   \n",
      "6309  zyyql5         SoulxShadow  HarryPotterBooks   \n",
      "6310  zz9rn1    Always-bi-myself  HarryPotterBooks   \n",
      "\n",
      "                                                  title  \\\n",
      "0     Jim Dale changing his pronunciation of Voldemo...   \n",
      "1                                  Snape and Occlumency   \n",
      "2                   Your favorite Harry Potter fan art?   \n",
      "3                                    Selective Security   \n",
      "4               Isn't Harry kind of a jerk to Hermione?   \n",
      "...                                                 ...   \n",
      "6306                  Discrepancy in Half Blood Prince?   \n",
      "6307                         Wallpaper for the 7 movies   \n",
      "6308  I think the trios friendship would be unreali...   \n",
      "6309       What is your detailed opinion of Dumbledore?   \n",
      "6310  Dumbledore fucked around &amp; found out  but...   \n",
      "\n",
      "                                               selftext  \n",
      "0     In the first 3 books he very clearly says it t...  \n",
      "1     Is Snape the most accomplished occlumence of a...  \n",
      "2                                             [deleted]  \n",
      "3     Malfoys scheme in HBP was to fix the vanishin...  \n",
      "4     Just rereading the Harry Potter books (up to t...  \n",
      "...                                                 ...  \n",
      "6306  Im listening to the audio books at the moment...  \n",
      "6307                                          [removed]  \n",
      "6308  I think they have such a beautiful and strong ...  \n",
      "6309                                                     \n",
      "6310  **This was created after someone here asked fo...  \n",
      "\n",
      "[6311 rows x 5 columns]\n",
      "           id           author    link_id   parent_id         subreddit  \\\n",
      "0     ceff2fg        [deleted]  t3_1tcbbk   t3_1tcbbk  HarryPotterBooks   \n",
      "1     cegbo9j          GameOfT  t3_1tcbbk   t3_1tcbbk  HarryPotterBooks   \n",
      "2     cejfxkq            Rjr18  t3_1ulye4   t3_1ulye4  HarryPotterBooks   \n",
      "3     cejgivj   MilkIsMyPotion  t3_1ulye4   t3_1ulye4  HarryPotterBooks   \n",
      "4     cejkfmq  GaslightProphet  t3_1sp5h8  t1_ce040as  HarryPotterBooks   \n",
      "...       ...              ...        ...         ...               ...   \n",
      "9812  fg4jrgz      freakbiotic  t3_ewtteg   t3_ewtteg  HarryPotterBooks   \n",
      "9813  fg4km28    Chinoiserie91  t3_ewtteg   t3_ewtteg  HarryPotterBooks   \n",
      "9814  fg4kqph     dsjunior1388  t3_ewtteg   t3_ewtteg  HarryPotterBooks   \n",
      "9815  fg4mgwf      batjeep1981  t3_ewtteg   t3_ewtteg  HarryPotterBooks   \n",
      "9816  fg4qasu     countrandall  t3_ewtteg   t3_ewtteg  HarryPotterBooks   \n",
      "\n",
      "                                                   body  \n",
      "0                                             [deleted]  \n",
      "1     There are a lot of twists and turns throughout...  \n",
      "2     Easily the Half-Blood Prince. I think it has t...  \n",
      "3     Its GoF. Not only because it was my first Harr...  \n",
      "4            Didnt the movies pronounce it Her-My-Knee?  \n",
      "...                                                 ...  \n",
      "9812  I agree with you, I never supported this relat...  \n",
      "9813  Well what you are saying is true. However him ...  \n",
      "9814  Many people have a tendency to revert to their...  \n",
      "9815       To me the worst part is the Cursed Child. /s  \n",
      "9816  I think the exact opposite? Just because your...  \n",
      "\n",
      "[9817 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(harry_potter_books_submissions)\n",
    "print(harry_potter_books_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "567b8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 't3_' prefix from the link_id column in the comments DataFrame\n",
    "harry_potter_books_comments['link_id'] = harry_potter_books_comments['link_id'].str.replace('t3_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "95ba1db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id_comment author_comment link_id   parent_id subreddit_comment  \\\n",
      "0    ds12yz3        jhynezz  7ndcao   t3_7ndcao  HarryPotterBooks   \n",
      "1    ds1e4sc     joriebooks  7ndcao   t3_7ndcao  HarryPotterBooks   \n",
      "2    ds1gh8z  severusvape69  7ndcao   t3_7ndcao  HarryPotterBooks   \n",
      "3    ds2jco5    stiinabiina  7ndcao  t1_ds1e4sc  HarryPotterBooks   \n",
      "4    ds2jdfi    stiinabiina  7ndcao  t1_ds12yz3  HarryPotterBooks   \n",
      "\n",
      "                                                body id_submission  \\\n",
      "0  I love these audiobooks and Jim dales voice is...        7ndcao   \n",
      "1  Ive heard that it was because the movies star...        7ndcao   \n",
      "2                    More of a Stephen Fry kinda guy        7ndcao   \n",
      "3  Ah. That's what I suspected but hoped I was wr...        7ndcao   \n",
      "4      Thanks...sorry to ruin it for yoi. Obliviate!        7ndcao   \n",
      "\n",
      "  author_submission subreddit_submission  \\\n",
      "0       stiinabiina     HarryPotterBooks   \n",
      "1       stiinabiina     HarryPotterBooks   \n",
      "2       stiinabiina     HarryPotterBooks   \n",
      "3       stiinabiina     HarryPotterBooks   \n",
      "4       stiinabiina     HarryPotterBooks   \n",
      "\n",
      "                                               title  \\\n",
      "0  Jim Dale changing his pronunciation of Voldemo...   \n",
      "1  Jim Dale changing his pronunciation of Voldemo...   \n",
      "2  Jim Dale changing his pronunciation of Voldemo...   \n",
      "3  Jim Dale changing his pronunciation of Voldemo...   \n",
      "4  Jim Dale changing his pronunciation of Voldemo...   \n",
      "\n",
      "                                            selftext  \n",
      "0  In the first 3 books he very clearly says it t...  \n",
      "1  In the first 3 books he very clearly says it t...  \n",
      "2  In the first 3 books he very clearly says it t...  \n",
      "3  In the first 3 books he very clearly says it t...  \n",
      "4  In the first 3 books he very clearly says it t...  \n"
     ]
    }
   ],
   "source": [
    "# Merge the submissions and comments DataFrames on the id and link_id columns\n",
    "merged_df = harry_potter_books_comments.merge(harry_potter_books_submissions, left_on='link_id', right_on='id', suffixes=('_comment', '_submission'))\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "081e7ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame Columns:\n",
      "Index(['id_comment', 'author_comment', 'link_id', 'parent_id',\n",
      "       'subreddit_comment', 'body', 'id_submission', 'author_submission',\n",
      "       'subreddit_submission', 'title', 'selftext'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Merged DataFrame Columns:\")\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e0a5d667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the cleaned DataFrame:\n",
      "Index(['id_comment', 'author_comment', 'parent_id', 'body', 'id_submission',\n",
      "       'author_submission', 'subreddit_submission', 'title', 'selftext'],\n",
      "      dtype='object')\n",
      "\n",
      "First few rows of the cleaned DataFrame:\n",
      "  id_comment author_comment   parent_id  \\\n",
      "0    ds12yz3        jhynezz   t3_7ndcao   \n",
      "1    ds1e4sc     joriebooks   t3_7ndcao   \n",
      "2    ds1gh8z  severusvape69   t3_7ndcao   \n",
      "3    ds2jco5    stiinabiina  t1_ds1e4sc   \n",
      "4    ds2jdfi    stiinabiina  t1_ds12yz3   \n",
      "\n",
      "                                                body id_submission  \\\n",
      "0  I love these audiobooks and Jim dales voice is...        7ndcao   \n",
      "1  Ive heard that it was because the movies star...        7ndcao   \n",
      "2                    More of a Stephen Fry kinda guy        7ndcao   \n",
      "3  Ah. That's what I suspected but hoped I was wr...        7ndcao   \n",
      "4      Thanks...sorry to ruin it for yoi. Obliviate!        7ndcao   \n",
      "\n",
      "  author_submission subreddit_submission  \\\n",
      "0       stiinabiina     HarryPotterBooks   \n",
      "1       stiinabiina     HarryPotterBooks   \n",
      "2       stiinabiina     HarryPotterBooks   \n",
      "3       stiinabiina     HarryPotterBooks   \n",
      "4       stiinabiina     HarryPotterBooks   \n",
      "\n",
      "                                               title  \\\n",
      "0  Jim Dale changing his pronunciation of Voldemo...   \n",
      "1  Jim Dale changing his pronunciation of Voldemo...   \n",
      "2  Jim Dale changing his pronunciation of Voldemo...   \n",
      "3  Jim Dale changing his pronunciation of Voldemo...   \n",
      "4  Jim Dale changing his pronunciation of Voldemo...   \n",
      "\n",
      "                                            selftext  \n",
      "0  In the first 3 books he very clearly says it t...  \n",
      "1  In the first 3 books he very clearly says it t...  \n",
      "2  In the first 3 books he very clearly says it t...  \n",
      "3  In the first 3 books he very clearly says it t...  \n",
      "4  In the first 3 books he very clearly says it t...  \n"
     ]
    }
   ],
   "source": [
    "# Remove the redundant columns\n",
    "merged_df.drop(columns=['link_id', 'subreddit_comment'], inplace=True)\n",
    "\n",
    "print(\"Columns in the cleaned DataFrame:\")\n",
    "print(merged_df.columns)\n",
    "\n",
    "print(\"\\nFirst few rows of the cleaned DataFrame:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b50808d",
   "metadata": {},
   "source": [
    "### Cleaning and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9e3a86c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with '[deleted]' in the 'body' column\n",
    "harrypotterbooks_df = merged_df[merged_df['body'] != '[deleted]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ba8d199b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\1141821689.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  harrypotterbooks_df['body'] = harrypotterbooks_df['body'].str.lower()\n",
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\1141821689.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  harrypotterbooks_df['selftext'] = harrypotterbooks_df['selftext'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# Lowercase 'body' column\n",
    "harrypotterbooks_df['body'] = harrypotterbooks_df['body'].str.lower()\n",
    "\n",
    "# Lowercase 'selftext' column\n",
    "harrypotterbooks_df['selftext'] = harrypotterbooks_df['selftext'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0103864a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\1164956153.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  harrypotterbooks_df[text_columns] = harrypotterbooks_df[text_columns].applymap(remove_punctuation)\n"
     ]
    }
   ],
   "source": [
    "# Define a function to remove punctuation from a string\n",
    "def remove_punctuation(text):\n",
    "    # Get the predefined set of punctuation characters\n",
    "    punctuation_set = set(string.punctuation)\n",
    "    # Use ''.join() to remove punctuation\n",
    "    return ''.join(char for char in text if char not in punctuation_set)\n",
    "\n",
    "# Remove punctuation from the relevant columns\n",
    "text_columns = ['body', 'selftext']\n",
    "harrypotterbooks_df[text_columns] = harrypotterbooks_df[text_columns].applymap(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e273b482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\3821233411.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  harrypotterbooks_df['body'] = harrypotterbooks_df['body'].str.replace('\\n\\n', ' ')\n",
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\3821233411.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  harrypotterbooks_df['selftext'] = harrypotterbooks_df['selftext'].str.replace('\\n\\n', ' ')\n"
     ]
    }
   ],
   "source": [
    "# Replace '\\n\\n' with a space in the 'body' and 'selftext' columns\n",
    "harrypotterbooks_df['body'] = harrypotterbooks_df['body'].str.replace('\\n\\n', ' ')\n",
    "harrypotterbooks_df['selftext'] = harrypotterbooks_df['selftext'].str.replace('\\n\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c71fa26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to C:\\Users\\josie\\Downloads\\REDDIT_HPBOOKS_DATA_CLEANED.txt\n"
     ]
    }
   ],
   "source": [
    "cleaned_file_path = r'C:\\Users\\josie\\Downloads\\REDDIT_HPBOOKS_DATA_CLEANED.txt'\n",
    "harrypotterbooks_df.to_csv(cleaned_file_path, index=False, sep='\\t')\n",
    "\n",
    "print(f\"Cleaned data saved to {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f22ceb",
   "metadata": {},
   "source": [
    "## Now save all relevant columns and groupings as needed as .txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2b24b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\1760575593.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  harrypotterbooks_df['body'] = harrypotterbooks_df['body'].apply(word_tokenize)\n",
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\1760575593.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  harrypotterbooks_df['selftext'] = harrypotterbooks_df['selftext'].apply(word_tokenize)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "harrypotterbooks_df['body'] = harrypotterbooks_df['body'].apply(word_tokenize)\n",
    "harrypotterbooks_df['selftext'] = harrypotterbooks_df['selftext'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5372d995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\2129535206.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  harrypotterbooks_df['body'] = harrypotterbooks_df['body'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\2129535206.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  harrypotterbooks_df['selftext'] = harrypotterbooks_df['selftext'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords from the tokenized 'body' column\n",
    "harrypotterbooks_df['body'] = harrypotterbooks_df['body'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
    "\n",
    "# Remove stopwords from the tokenized 'selftext' column\n",
    "harrypotterbooks_df['selftext'] = harrypotterbooks_df['selftext'].apply(lambda x: [word for word in x if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8292abb",
   "metadata": {},
   "source": [
    "Final check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a4883ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_comment</th>\n",
       "      <th>author_comment</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>body</th>\n",
       "      <th>id_submission</th>\n",
       "      <th>author_submission</th>\n",
       "      <th>subreddit_submission</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ds12yz3</td>\n",
       "      <td>jhynezz</td>\n",
       "      <td>t3_7ndcao</td>\n",
       "      <td>[love, audiobooks, jim, dales, voice, life, ,...</td>\n",
       "      <td>7ndcao</td>\n",
       "      <td>stiinabiina</td>\n",
       "      <td>HarryPotterBooks</td>\n",
       "      <td>Jim Dale changing his pronunciation of Voldemo...</td>\n",
       "      <td>[first, 3, books, clearly, says, jkr, way, vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ds1e4sc</td>\n",
       "      <td>joriebooks</td>\n",
       "      <td>t3_7ndcao</td>\n",
       "      <td>[, heard, movies, started, saying, voldemort]</td>\n",
       "      <td>7ndcao</td>\n",
       "      <td>stiinabiina</td>\n",
       "      <td>HarryPotterBooks</td>\n",
       "      <td>Jim Dale changing his pronunciation of Voldemo...</td>\n",
       "      <td>[first, 3, books, clearly, says, jkr, way, vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ds1gh8z</td>\n",
       "      <td>severusvape69</td>\n",
       "      <td>t3_7ndcao</td>\n",
       "      <td>[stephen, fry, kinda, guy]</td>\n",
       "      <td>7ndcao</td>\n",
       "      <td>stiinabiina</td>\n",
       "      <td>HarryPotterBooks</td>\n",
       "      <td>Jim Dale changing his pronunciation of Voldemo...</td>\n",
       "      <td>[first, 3, books, clearly, says, jkr, way, vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ds2jco5</td>\n",
       "      <td>stiinabiina</td>\n",
       "      <td>t1_ds1e4sc</td>\n",
       "      <td>[ah, thats, suspected, hoped, wrong, ugh, foll...</td>\n",
       "      <td>7ndcao</td>\n",
       "      <td>stiinabiina</td>\n",
       "      <td>HarryPotterBooks</td>\n",
       "      <td>Jim Dale changing his pronunciation of Voldemo...</td>\n",
       "      <td>[first, 3, books, clearly, says, jkr, way, vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ds2jdfi</td>\n",
       "      <td>stiinabiina</td>\n",
       "      <td>t1_ds12yz3</td>\n",
       "      <td>[thankssorry, ruin, yoi, obliviate]</td>\n",
       "      <td>7ndcao</td>\n",
       "      <td>stiinabiina</td>\n",
       "      <td>HarryPotterBooks</td>\n",
       "      <td>Jim Dale changing his pronunciation of Voldemo...</td>\n",
       "      <td>[first, 3, books, clearly, says, jkr, way, vol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7093</th>\n",
       "      <td>fg4jrgz</td>\n",
       "      <td>freakbiotic</td>\n",
       "      <td>t3_ewtteg</td>\n",
       "      <td>[agree, never, supported, relationship, ron, a...</td>\n",
       "      <td>ewtteg</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>HarryPotterBooks</td>\n",
       "      <td>The most frustrating part of the epilogue is R...</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7094</th>\n",
       "      <td>fg4km28</td>\n",
       "      <td>Chinoiserie91</td>\n",
       "      <td>t3_ewtteg</td>\n",
       "      <td>[well, saying, true, however, joking, one, inc...</td>\n",
       "      <td>ewtteg</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>HarryPotterBooks</td>\n",
       "      <td>The most frustrating part of the epilogue is R...</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7095</th>\n",
       "      <td>fg4kqph</td>\n",
       "      <td>dsjunior1388</td>\n",
       "      <td>t3_ewtteg</td>\n",
       "      <td>[many, people, tendency, revert, younger, pers...</td>\n",
       "      <td>ewtteg</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>HarryPotterBooks</td>\n",
       "      <td>The most frustrating part of the epilogue is R...</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>fg4mgwf</td>\n",
       "      <td>batjeep1981</td>\n",
       "      <td>t3_ewtteg</td>\n",
       "      <td>[worst, part, cursed, child]</td>\n",
       "      <td>ewtteg</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>HarryPotterBooks</td>\n",
       "      <td>The most frustrating part of the epilogue is R...</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>fg4qasu</td>\n",
       "      <td>countrandall</td>\n",
       "      <td>t3_ewtteg</td>\n",
       "      <td>[think, exact, opposite, , adult, , mean, ac...</td>\n",
       "      <td>ewtteg</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>HarryPotterBooks</td>\n",
       "      <td>The most frustrating part of the epilogue is R...</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6954 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_comment author_comment   parent_id  \\\n",
       "0       ds12yz3        jhynezz   t3_7ndcao   \n",
       "1       ds1e4sc     joriebooks   t3_7ndcao   \n",
       "2       ds1gh8z  severusvape69   t3_7ndcao   \n",
       "3       ds2jco5    stiinabiina  t1_ds1e4sc   \n",
       "4       ds2jdfi    stiinabiina  t1_ds12yz3   \n",
       "...         ...            ...         ...   \n",
       "7093    fg4jrgz    freakbiotic   t3_ewtteg   \n",
       "7094    fg4km28  Chinoiserie91   t3_ewtteg   \n",
       "7095    fg4kqph   dsjunior1388   t3_ewtteg   \n",
       "7096    fg4mgwf    batjeep1981   t3_ewtteg   \n",
       "7097    fg4qasu   countrandall   t3_ewtteg   \n",
       "\n",
       "                                                   body id_submission  \\\n",
       "0     [love, audiobooks, jim, dales, voice, life, ,...        7ndcao   \n",
       "1        [, heard, movies, started, saying, voldemort]        7ndcao   \n",
       "2                            [stephen, fry, kinda, guy]        7ndcao   \n",
       "3     [ah, thats, suspected, hoped, wrong, ugh, foll...        7ndcao   \n",
       "4                   [thankssorry, ruin, yoi, obliviate]        7ndcao   \n",
       "...                                                 ...           ...   \n",
       "7093  [agree, never, supported, relationship, ron, a...        ewtteg   \n",
       "7094  [well, saying, true, however, joking, one, inc...        ewtteg   \n",
       "7095  [many, people, tendency, revert, younger, pers...        ewtteg   \n",
       "7096                       [worst, part, cursed, child]        ewtteg   \n",
       "7097  [think, exact, opposite, , adult, , mean, ac...        ewtteg   \n",
       "\n",
       "     author_submission subreddit_submission  \\\n",
       "0          stiinabiina     HarryPotterBooks   \n",
       "1          stiinabiina     HarryPotterBooks   \n",
       "2          stiinabiina     HarryPotterBooks   \n",
       "3          stiinabiina     HarryPotterBooks   \n",
       "4          stiinabiina     HarryPotterBooks   \n",
       "...                ...                  ...   \n",
       "7093         [deleted]     HarryPotterBooks   \n",
       "7094         [deleted]     HarryPotterBooks   \n",
       "7095         [deleted]     HarryPotterBooks   \n",
       "7096         [deleted]     HarryPotterBooks   \n",
       "7097         [deleted]     HarryPotterBooks   \n",
       "\n",
       "                                                  title  \\\n",
       "0     Jim Dale changing his pronunciation of Voldemo...   \n",
       "1     Jim Dale changing his pronunciation of Voldemo...   \n",
       "2     Jim Dale changing his pronunciation of Voldemo...   \n",
       "3     Jim Dale changing his pronunciation of Voldemo...   \n",
       "4     Jim Dale changing his pronunciation of Voldemo...   \n",
       "...                                                 ...   \n",
       "7093  The most frustrating part of the epilogue is R...   \n",
       "7094  The most frustrating part of the epilogue is R...   \n",
       "7095  The most frustrating part of the epilogue is R...   \n",
       "7096  The most frustrating part of the epilogue is R...   \n",
       "7097  The most frustrating part of the epilogue is R...   \n",
       "\n",
       "                                               selftext  \n",
       "0     [first, 3, books, clearly, says, jkr, way, vol...  \n",
       "1     [first, 3, books, clearly, says, jkr, way, vol...  \n",
       "2     [first, 3, books, clearly, says, jkr, way, vol...  \n",
       "3     [first, 3, books, clearly, says, jkr, way, vol...  \n",
       "4     [first, 3, books, clearly, says, jkr, way, vol...  \n",
       "...                                                 ...  \n",
       "7093                                          [deleted]  \n",
       "7094                                          [deleted]  \n",
       "7095                                          [deleted]  \n",
       "7096                                          [deleted]  \n",
       "7097                                          [deleted]  \n",
       "\n",
       "[6954 rows x 9 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harrypotterbooks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d6abc5",
   "metadata": {},
   "source": [
    "# \"r/KnivesOutMovie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "be20ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to the folder containing the Harry Potter pickle files\n",
    "folder_path = r'C:\\Users\\josie\\OneDrive\\Desktop\\Reddit\\KnivesOutMovie'\n",
    "\n",
    "# List all the pickle files that the folder contains\n",
    "pickle_files = [file for file in os.listdir(folder_path) if file.startswith('subreddit_KnivesOutMovie')]\n",
    "\n",
    "# Initialize empty dictionary to store loaded data\n",
    "knivesout_data = {}\n",
    "\n",
    "# Load each pickle file and store its contents in the dictionary\n",
    "for file_name in pickle_files:\n",
    "    with open(os.path.join(folder_path, file_name), 'rb') as f:\n",
    "        knivesout_data[file_name] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a39b4238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: subreddit_KnivesOutMovie_RC_2021-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RC_2021-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RC_2021-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RC_2021-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RC_2021-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RC_2021-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RC_2021-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RC_2021-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RC_2021-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RC_2021-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RC_2021-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RC_2021-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RS_2021-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RS_2021-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RS_2021-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RS_2021-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RS_2021-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RS_2021-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RS_2021-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RS_2021-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RS_2021-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RS_2021-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_KnivesOutMovie_RS_2021-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each pickle file and inspect its contents\n",
    "for file_name, data in knivesout_data.items():\n",
    "    print(f\"File: {file_name}\")\n",
    "    print(f\"Data type: {type(data)}\")\n",
    "    print(f\"Keys: {data.keys()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2a559178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries to store RS (Reddit submissions) and RC (Reddit comments) DataFrames\n",
    "rs_data = {}\n",
    "rc_data = {}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a Reddit submission file\n",
    "    if file_name.startswith(\"subreddit_KnivesOutMovie_RS\"):\n",
    "        # Load the RS DataFrame and store it in the dictionary with the corresponding date as the key\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rs_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "    \n",
    "    # Check if the file is a Reddit comment file\n",
    "    elif file_name.startswith(\"subreddit_KnivesOutMovie_RC\"):\n",
    "        # Load the RC DataFrame and store it in the dictionary with the corresponding date as the key\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rc_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "\n",
    "# Concatenate all the RS DataFrames into a single DataFrame\n",
    "knivesout_submissions = pd.concat(rs_data.values(), ignore_index=True)\n",
    "\n",
    "# Concatenate all the RC DataFrames into a single DataFrame\n",
    "knivesout_comments = pd.concat(rc_data.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42475b5c",
   "metadata": {},
   "source": [
    "Check again if the link_id column for this set of data also begins with \"t3_\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "67135a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values in 'link_id' column start with 't3_' or 't1_': True\n"
     ]
    }
   ],
   "source": [
    "# Check if all values in 'link_id' column start with 't3_'\n",
    "all_values_start_with_t3 = knivesout_comments['link_id'].str.startswith('t3_').all()\n",
    "\n",
    "print(\"All values in 'link_id' column start with 't3_' or 't1_':\", all_values_start_with_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "878c3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 't3_' prefix from the link_id column in the comments DataFrame\n",
    "knivesout_comments['link_id'] = knivesout_comments['link_id'].str.replace('t3_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ecc67ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id_comment    author_comment link_id  parent_id subreddit_comment  \\\n",
      "0    gjiw3t0       ilinamorato  kylrw7  t3_kylrw7    KnivesOutMovie   \n",
      "1    gmlib2b  SheDaisy11151979  kylrw7  t3_kylrw7    KnivesOutMovie   \n",
      "2    gk4ch8o   agentgravyphone  l2aivu  t3_l2aivu    KnivesOutMovie   \n",
      "3    gk5987d   ErinEqualsPeace  l2aivu  t3_l2aivu    KnivesOutMovie   \n",
      "4    gk63dxm         xeroxgirl  l2aivu  t3_l2aivu    KnivesOutMovie   \n",
      "\n",
      "                                                body id_submission  \\\n",
      "0  Benoit explains in the next line. Because he d...        kylrw7   \n",
      "1  Ransom thought that he'd successfully poisoned...        kylrw7   \n",
      "2  I think she might have given them a bit of mon...        l2aivu   \n",
      "3  She would probably need a fair amount for prop...        l2aivu   \n",
      "4  Let's put something out there. They're not act...        l2aivu   \n",
      "\n",
      "  author_submission subreddit_submission  \\\n",
      "0         imnotsus_       KnivesOutMovie   \n",
      "1         imnotsus_       KnivesOutMovie   \n",
      "2  SheDaisy11151979       KnivesOutMovie   \n",
      "3  SheDaisy11151979       KnivesOutMovie   \n",
      "4  SheDaisy11151979       KnivesOutMovie   \n",
      "\n",
      "                                     title  \\\n",
      "0               Something odd with Ransom.   \n",
      "1               Something odd with Ransom.   \n",
      "2  What did Marta end up doing in the end?   \n",
      "3  What did Marta end up doing in the end?   \n",
      "4  What did Marta end up doing in the end?   \n",
      "\n",
      "                                            selftext  \n",
      "0  We see that when Mr.Blanc was revealing the my...  \n",
      "1  We see that when Mr.Blanc was revealing the my...  \n",
      "2  I find myself wondering how Marta dealt with t...  \n",
      "3  I find myself wondering how Marta dealt with t...  \n",
      "4  I find myself wondering how Marta dealt with t...  \n"
     ]
    }
   ],
   "source": [
    "# Merge the submissions and comments DataFrames on the id and link_id columns\n",
    "merged_df = knivesout_comments.merge(knivesout_submissions, left_on='link_id', right_on='id', suffixes=('_comment', '_submission'))\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e724f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knivesout_df = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cb2aca5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id_comment    author_comment link_id  parent_id subreddit_comment  \\\n",
      "0    gjiw3t0       ilinamorato  kylrw7  t3_kylrw7    KnivesOutMovie   \n",
      "1    gmlib2b  SheDaisy11151979  kylrw7  t3_kylrw7    KnivesOutMovie   \n",
      "2    gk4ch8o   agentgravyphone  l2aivu  t3_l2aivu    KnivesOutMovie   \n",
      "3    gk5987d   ErinEqualsPeace  l2aivu  t3_l2aivu    KnivesOutMovie   \n",
      "4    gk63dxm         xeroxgirl  l2aivu  t3_l2aivu    KnivesOutMovie   \n",
      "\n",
      "                                                body author_submission  \\\n",
      "0  Benoit explains in the next line. Because he d...         imnotsus_   \n",
      "1  Ransom thought that he'd successfully poisoned...         imnotsus_   \n",
      "2  I think she might have given them a bit of mon...  SheDaisy11151979   \n",
      "3  She would probably need a fair amount for prop...  SheDaisy11151979   \n",
      "4  Let's put something out there. They're not act...  SheDaisy11151979   \n",
      "\n",
      "  subreddit_submission                                    title  \\\n",
      "0       KnivesOutMovie               Something odd with Ransom.   \n",
      "1       KnivesOutMovie               Something odd with Ransom.   \n",
      "2       KnivesOutMovie  What did Marta end up doing in the end?   \n",
      "3       KnivesOutMovie  What did Marta end up doing in the end?   \n",
      "4       KnivesOutMovie  What did Marta end up doing in the end?   \n",
      "\n",
      "                                            selftext  \n",
      "0  We see that when Mr.Blanc was revealing the my...  \n",
      "1  We see that when Mr.Blanc was revealing the my...  \n",
      "2  I find myself wondering how Marta dealt with t...  \n",
      "3  I find myself wondering how Marta dealt with t...  \n",
      "4  I find myself wondering how Marta dealt with t...  \n"
     ]
    }
   ],
   "source": [
    "# Remove the redundant columns\n",
    "#'cleaned_link_id' appears twice in the DataFrame\n",
    "knivesout_df = knivesout_df.drop(['id_submission'], axis=1)\n",
    "\n",
    "print(knivesout_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "544b3cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_comment</th>\n",
       "      <th>author_comment</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>subreddit_comment</th>\n",
       "      <th>body</th>\n",
       "      <th>author_submission</th>\n",
       "      <th>subreddit_submission</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gjiw3t0</td>\n",
       "      <td>ilinamorato</td>\n",
       "      <td>kylrw7</td>\n",
       "      <td>t3_kylrw7</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>Benoit explains in the next line. Because he d...</td>\n",
       "      <td>imnotsus_</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>Something odd with Ransom.</td>\n",
       "      <td>We see that when Mr.Blanc was revealing the my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gmlib2b</td>\n",
       "      <td>SheDaisy11151979</td>\n",
       "      <td>kylrw7</td>\n",
       "      <td>t3_kylrw7</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>Ransom thought that he'd successfully poisoned...</td>\n",
       "      <td>imnotsus_</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>Something odd with Ransom.</td>\n",
       "      <td>We see that when Mr.Blanc was revealing the my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gk4ch8o</td>\n",
       "      <td>agentgravyphone</td>\n",
       "      <td>l2aivu</td>\n",
       "      <td>t3_l2aivu</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>I think she might have given them a bit of mon...</td>\n",
       "      <td>SheDaisy11151979</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>What did Marta end up doing in the end?</td>\n",
       "      <td>I find myself wondering how Marta dealt with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gk5987d</td>\n",
       "      <td>ErinEqualsPeace</td>\n",
       "      <td>l2aivu</td>\n",
       "      <td>t3_l2aivu</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>She would probably need a fair amount for prop...</td>\n",
       "      <td>SheDaisy11151979</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>What did Marta end up doing in the end?</td>\n",
       "      <td>I find myself wondering how Marta dealt with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gk63dxm</td>\n",
       "      <td>xeroxgirl</td>\n",
       "      <td>l2aivu</td>\n",
       "      <td>t3_l2aivu</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>Let's put something out there. They're not act...</td>\n",
       "      <td>SheDaisy11151979</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>What did Marta end up doing in the end?</td>\n",
       "      <td>I find myself wondering how Marta dealt with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>hh06rn7</td>\n",
       "      <td>Creepy_Willow9842</td>\n",
       "      <td>q47l24</td>\n",
       "      <td>t3_q47l24</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>Honestly though the difference ends with some ...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>[deleted by user]</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>hmbtue9</td>\n",
       "      <td>The_Molsen</td>\n",
       "      <td>r38frz</td>\n",
       "      <td>t3_r38frz</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>It was implied that it was some kind of social...</td>\n",
       "      <td>Bahamaunt</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>So what did Meg study anyway??</td>\n",
       "      <td>She immediately sold out Marta when she reali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>hmcgobc</td>\n",
       "      <td>Bahamaunt</td>\n",
       "      <td>r38frz</td>\n",
       "      <td>t1_hmbtue9</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>I'm not very knowledgeable on the matter, so ...</td>\n",
       "      <td>Bahamaunt</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>So what did Meg study anyway??</td>\n",
       "      <td>She immediately sold out Marta when she reali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>hqjqgw2</td>\n",
       "      <td>CT-0614</td>\n",
       "      <td>rs25y6</td>\n",
       "      <td>t3_rs25y6</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>She opened the door when he did it</td>\n",
       "      <td>Just-Breadfruit5742</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>How did Martha get a blood spot on her shoe?</td>\n",
       "      <td>This question has been on my mind for a while....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>hql1eh2</td>\n",
       "      <td>altariawesome</td>\n",
       "      <td>rs25y6</td>\n",
       "      <td>t3_rs25y6</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>I've always put it down to arterial spray in a...</td>\n",
       "      <td>Just-Breadfruit5742</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>How did Martha get a blood spot on her shoe?</td>\n",
       "      <td>This question has been on my mind for a while....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_comment     author_comment link_id   parent_id subreddit_comment  \\\n",
       "0      gjiw3t0        ilinamorato  kylrw7   t3_kylrw7    KnivesOutMovie   \n",
       "1      gmlib2b   SheDaisy11151979  kylrw7   t3_kylrw7    KnivesOutMovie   \n",
       "2      gk4ch8o    agentgravyphone  l2aivu   t3_l2aivu    KnivesOutMovie   \n",
       "3      gk5987d    ErinEqualsPeace  l2aivu   t3_l2aivu    KnivesOutMovie   \n",
       "4      gk63dxm          xeroxgirl  l2aivu   t3_l2aivu    KnivesOutMovie   \n",
       "..         ...                ...     ...         ...               ...   \n",
       "122    hh06rn7  Creepy_Willow9842  q47l24   t3_q47l24    KnivesOutMovie   \n",
       "123    hmbtue9         The_Molsen  r38frz   t3_r38frz    KnivesOutMovie   \n",
       "124    hmcgobc          Bahamaunt  r38frz  t1_hmbtue9    KnivesOutMovie   \n",
       "125    hqjqgw2            CT-0614  rs25y6   t3_rs25y6    KnivesOutMovie   \n",
       "126    hql1eh2      altariawesome  rs25y6   t3_rs25y6    KnivesOutMovie   \n",
       "\n",
       "                                                  body    author_submission  \\\n",
       "0    Benoit explains in the next line. Because he d...            imnotsus_   \n",
       "1    Ransom thought that he'd successfully poisoned...            imnotsus_   \n",
       "2    I think she might have given them a bit of mon...     SheDaisy11151979   \n",
       "3    She would probably need a fair amount for prop...     SheDaisy11151979   \n",
       "4    Let's put something out there. They're not act...     SheDaisy11151979   \n",
       "..                                                 ...                  ...   \n",
       "122  Honestly though the difference ends with some ...            [deleted]   \n",
       "123  It was implied that it was some kind of social...            Bahamaunt   \n",
       "124   I'm not very knowledgeable on the matter, so ...            Bahamaunt   \n",
       "125                 She opened the door when he did it  Just-Breadfruit5742   \n",
       "126  I've always put it down to arterial spray in a...  Just-Breadfruit5742   \n",
       "\n",
       "    subreddit_submission                                         title  \\\n",
       "0         KnivesOutMovie                    Something odd with Ransom.   \n",
       "1         KnivesOutMovie                    Something odd with Ransom.   \n",
       "2         KnivesOutMovie       What did Marta end up doing in the end?   \n",
       "3         KnivesOutMovie       What did Marta end up doing in the end?   \n",
       "4         KnivesOutMovie       What did Marta end up doing in the end?   \n",
       "..                   ...                                           ...   \n",
       "122       KnivesOutMovie                             [deleted by user]   \n",
       "123       KnivesOutMovie                So what did Meg study anyway??   \n",
       "124       KnivesOutMovie                So what did Meg study anyway??   \n",
       "125       KnivesOutMovie  How did Martha get a blood spot on her shoe?   \n",
       "126       KnivesOutMovie  How did Martha get a blood spot on her shoe?   \n",
       "\n",
       "                                              selftext  \n",
       "0    We see that when Mr.Blanc was revealing the my...  \n",
       "1    We see that when Mr.Blanc was revealing the my...  \n",
       "2    I find myself wondering how Marta dealt with t...  \n",
       "3    I find myself wondering how Marta dealt with t...  \n",
       "4    I find myself wondering how Marta dealt with t...  \n",
       "..                                                 ...  \n",
       "122                                          [removed]  \n",
       "123   She immediately sold out Marta when she reali...  \n",
       "124   She immediately sold out Marta when she reali...  \n",
       "125  This question has been on my mind for a while....  \n",
       "126  This question has been on my mind for a while....  \n",
       "\n",
       "[127 rows x 10 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knivesout_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfa1f00",
   "metadata": {},
   "source": [
    "### Cleaning and Prepocessing Knives Out Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ad6b5ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with '[deleted]' in the 'body' column\n",
    "knivesout_df = knivesout_df[knivesout_df['body'] != '[deleted]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0cc66f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\1941238529.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  knivesout_df['body'] = knivesout_df['body'].str.lower()\n",
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\1941238529.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  knivesout_df['selftext'] = knivesout_df['selftext'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# Lowercase 'body' column\n",
    "knivesout_df['body'] = knivesout_df['body'].str.lower()\n",
    "\n",
    "# Lowercase 'selftext' column\n",
    "knivesout_df['selftext'] = knivesout_df['selftext'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cea88af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\710959950.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  knivesout_df[text_columns] = knivesout_df[text_columns].applymap(remove_punctuation)\n"
     ]
    }
   ],
   "source": [
    "# Define a function to remove punctuation from a string\n",
    "def remove_punctuation(text):\n",
    "    # Get the predefined set of punctuation characters\n",
    "    punctuation_set = set(string.punctuation)\n",
    "    # Use ''.join() to remove punctuation\n",
    "    return ''.join(char for char in text if char not in punctuation_set)\n",
    "\n",
    "# Remove punctuation from the relevant columns\n",
    "text_columns = ['body', 'selftext']\n",
    "knivesout_df[text_columns] = knivesout_df[text_columns].applymap(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9f287770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\3298408617.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  knivesout_df['body'] = knivesout_df['body'].str.replace('\\n\\n', ' ')\n",
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\3298408617.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  knivesout_df['selftext'] = knivesout_df['selftext'].str.replace('\\n\\n', ' ')\n"
     ]
    }
   ],
   "source": [
    "# Replace '\\n\\n' with a space in the 'body' and 'selftext' columns\n",
    "knivesout_df['body'] = knivesout_df['body'].str.replace('\\n\\n', ' ')\n",
    "knivesout_df['selftext'] = knivesout_df['selftext'].str.replace('\\n\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d9c7e22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to C:\\Users\\josie\\Downloads\\REDDIT_KNIVESOUT_DATA_CLEANED.txt\n"
     ]
    }
   ],
   "source": [
    "cleaned_file_path = r'C:\\Users\\josie\\Downloads\\REDDIT_KNIVESOUT_DATA_CLEANED.txt'\n",
    "knivesout_df.to_csv(cleaned_file_path, index=False, sep='\\t')\n",
    "\n",
    "print(f\"Cleaned data saved to {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc833bb3",
   "metadata": {},
   "source": [
    "## Now save all relevant columns and groupings accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "aa2f71a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [we, see, that, when, mrblanc, was, revealing,...\n",
      "1      [we, see, that, when, mrblanc, was, revealing,...\n",
      "2      [i, find, myself, wondering, how, marta, dealt...\n",
      "3      [i, find, myself, wondering, how, marta, dealt...\n",
      "4      [i, find, myself, wondering, how, marta, dealt...\n",
      "                             ...                        \n",
      "122                                            [removed]\n",
      "123    [she, immediately, sold, out, marta, when, she...\n",
      "124    [she, immediately, sold, out, marta, when, she...\n",
      "125    [this, question, has, been, on, my, mind, for,...\n",
      "126    [this, question, has, been, on, my, mind, for,...\n",
      "Name: selftext, Length: 124, dtype: object\n",
      "0      [benoit, explains, in, the, next, line, becaus...\n",
      "1      [ransom, thought, that, hed, successfully, poi...\n",
      "2      [i, think, she, might, have, given, them, a, b...\n",
      "3      [she, would, probably, need, a, fair, amount, ...\n",
      "4      [lets, put, something, out, there, theyre, not...\n",
      "                             ...                        \n",
      "122    [honestly, though, the, difference, ends, with...\n",
      "123    [it, was, implied, that, it, was, some, kind, ...\n",
      "124    [im, not, very, knowledgeable, on, the, matter...\n",
      "125          [she, opened, the, door, when, he, did, it]\n",
      "126    [ive, always, put, it, down, to, arterial, spr...\n",
      "Name: body, Length: 124, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\800782111.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  knivesout_df['selftext'] = knivesout_df['selftext'].apply(word_tokenize)\n",
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\800782111.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  knivesout_df['body'] = knivesout_df['body'].apply(word_tokenize)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the body and selftext columns\n",
    "knivesout_df['selftext'] = knivesout_df['selftext'].apply(word_tokenize)\n",
    "knivesout_df['body'] = knivesout_df['body'].apply(word_tokenize)\n",
    "\n",
    "# Print the updated 'body' column\n",
    "print(knivesout_df['selftext'])\n",
    "print(knivesout_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "87063474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\2413960952.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  knivesout_df['body'] = knivesout_df['body'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
      "C:\\Users\\josie\\AppData\\Local\\Temp\\ipykernel_20688\\2413960952.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  knivesout_df['selftext'] = knivesout_df['selftext'].apply(lambda x: [word for word in x if word.lower() not in stop_words])# Define the stopwords\n"
     ]
    }
   ],
   "source": [
    "# Define the stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords from the tokenized 'body' column\n",
    "knivesout_df['body'] = knivesout_df['body'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
    "\n",
    "# Remove stopwords from the tokenized 'selftext' column\n",
    "knivesout_df['selftext'] = knivesout_df['selftext'].apply(lambda x: [word for word in x if word.lower() not in stop_words])# Define the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7766b4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_comment</th>\n",
       "      <th>author_comment</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>subreddit_comment</th>\n",
       "      <th>body</th>\n",
       "      <th>author_submission</th>\n",
       "      <th>subreddit_submission</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gjiw3t0</td>\n",
       "      <td>ilinamorato</td>\n",
       "      <td>kylrw7</td>\n",
       "      <td>t3_kylrw7</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>[benoit, explains, next, line, doesnt, know, t...</td>\n",
       "      <td>imnotsus_</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>Something odd with Ransom.</td>\n",
       "      <td>[see, mrblanc, revealing, mystery, says, ranso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gmlib2b</td>\n",
       "      <td>SheDaisy11151979</td>\n",
       "      <td>kylrw7</td>\n",
       "      <td>t3_kylrw7</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>[ransom, thought, hed, successfully, poisoned,...</td>\n",
       "      <td>imnotsus_</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>Something odd with Ransom.</td>\n",
       "      <td>[see, mrblanc, revealing, mystery, says, ranso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gk4ch8o</td>\n",
       "      <td>agentgravyphone</td>\n",
       "      <td>l2aivu</td>\n",
       "      <td>t3_l2aivu</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>[think, might, given, bit, money, like, enough...</td>\n",
       "      <td>SheDaisy11151979</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>What did Marta end up doing in the end?</td>\n",
       "      <td>[find, wondering, marta, dealt, inheritance, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gk5987d</td>\n",
       "      <td>ErinEqualsPeace</td>\n",
       "      <td>l2aivu</td>\n",
       "      <td>t3_l2aivu</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>[would, probably, need, fair, amount, property...</td>\n",
       "      <td>SheDaisy11151979</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>What did Marta end up doing in the end?</td>\n",
       "      <td>[find, wondering, marta, dealt, inheritance, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gk63dxm</td>\n",
       "      <td>xeroxgirl</td>\n",
       "      <td>l2aivu</td>\n",
       "      <td>t3_l2aivu</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>[lets, put, something, theyre, actually, broke...</td>\n",
       "      <td>SheDaisy11151979</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>What did Marta end up doing in the end?</td>\n",
       "      <td>[find, wondering, marta, dealt, inheritance, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>hh06rn7</td>\n",
       "      <td>Creepy_Willow9842</td>\n",
       "      <td>q47l24</td>\n",
       "      <td>t3_q47l24</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>[honestly, though, difference, ends, similarit...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>[deleted by user]</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>hmbtue9</td>\n",
       "      <td>The_Molsen</td>\n",
       "      <td>r38frz</td>\n",
       "      <td>t3_r38frz</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>[implied, kind, social, studies, x, justice, c...</td>\n",
       "      <td>Bahamaunt</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>So what did Meg study anyway??</td>\n",
       "      <td>[immediately, sold, marta, realized, mother, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>hmcgobc</td>\n",
       "      <td>Bahamaunt</td>\n",
       "      <td>r38frz</td>\n",
       "      <td>t1_hmbtue9</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>[im, knowledgeable, matter, would, social, stu...</td>\n",
       "      <td>Bahamaunt</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>So what did Meg study anyway??</td>\n",
       "      <td>[immediately, sold, marta, realized, mother, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>hqjqgw2</td>\n",
       "      <td>CT-0614</td>\n",
       "      <td>rs25y6</td>\n",
       "      <td>t3_rs25y6</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>[opened, door]</td>\n",
       "      <td>Just-Breadfruit5742</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>How did Martha get a blood spot on her shoe?</td>\n",
       "      <td>[question, mind, shown, one, scene, marthas, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>hql1eh2</td>\n",
       "      <td>altariawesome</td>\n",
       "      <td>rs25y6</td>\n",
       "      <td>t3_rs25y6</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>[ive, always, put, arterial, spray, enclosed, ...</td>\n",
       "      <td>Just-Breadfruit5742</td>\n",
       "      <td>KnivesOutMovie</td>\n",
       "      <td>How did Martha get a blood spot on her shoe?</td>\n",
       "      <td>[question, mind, shown, one, scene, marthas, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_comment     author_comment link_id   parent_id subreddit_comment  \\\n",
       "0      gjiw3t0        ilinamorato  kylrw7   t3_kylrw7    KnivesOutMovie   \n",
       "1      gmlib2b   SheDaisy11151979  kylrw7   t3_kylrw7    KnivesOutMovie   \n",
       "2      gk4ch8o    agentgravyphone  l2aivu   t3_l2aivu    KnivesOutMovie   \n",
       "3      gk5987d    ErinEqualsPeace  l2aivu   t3_l2aivu    KnivesOutMovie   \n",
       "4      gk63dxm          xeroxgirl  l2aivu   t3_l2aivu    KnivesOutMovie   \n",
       "..         ...                ...     ...         ...               ...   \n",
       "122    hh06rn7  Creepy_Willow9842  q47l24   t3_q47l24    KnivesOutMovie   \n",
       "123    hmbtue9         The_Molsen  r38frz   t3_r38frz    KnivesOutMovie   \n",
       "124    hmcgobc          Bahamaunt  r38frz  t1_hmbtue9    KnivesOutMovie   \n",
       "125    hqjqgw2            CT-0614  rs25y6   t3_rs25y6    KnivesOutMovie   \n",
       "126    hql1eh2      altariawesome  rs25y6   t3_rs25y6    KnivesOutMovie   \n",
       "\n",
       "                                                  body    author_submission  \\\n",
       "0    [benoit, explains, next, line, doesnt, know, t...            imnotsus_   \n",
       "1    [ransom, thought, hed, successfully, poisoned,...            imnotsus_   \n",
       "2    [think, might, given, bit, money, like, enough...     SheDaisy11151979   \n",
       "3    [would, probably, need, fair, amount, property...     SheDaisy11151979   \n",
       "4    [lets, put, something, theyre, actually, broke...     SheDaisy11151979   \n",
       "..                                                 ...                  ...   \n",
       "122  [honestly, though, difference, ends, similarit...            [deleted]   \n",
       "123  [implied, kind, social, studies, x, justice, c...            Bahamaunt   \n",
       "124  [im, knowledgeable, matter, would, social, stu...            Bahamaunt   \n",
       "125                                     [opened, door]  Just-Breadfruit5742   \n",
       "126  [ive, always, put, arterial, spray, enclosed, ...  Just-Breadfruit5742   \n",
       "\n",
       "    subreddit_submission                                         title  \\\n",
       "0         KnivesOutMovie                    Something odd with Ransom.   \n",
       "1         KnivesOutMovie                    Something odd with Ransom.   \n",
       "2         KnivesOutMovie       What did Marta end up doing in the end?   \n",
       "3         KnivesOutMovie       What did Marta end up doing in the end?   \n",
       "4         KnivesOutMovie       What did Marta end up doing in the end?   \n",
       "..                   ...                                           ...   \n",
       "122       KnivesOutMovie                             [deleted by user]   \n",
       "123       KnivesOutMovie                So what did Meg study anyway??   \n",
       "124       KnivesOutMovie                So what did Meg study anyway??   \n",
       "125       KnivesOutMovie  How did Martha get a blood spot on her shoe?   \n",
       "126       KnivesOutMovie  How did Martha get a blood spot on her shoe?   \n",
       "\n",
       "                                              selftext  \n",
       "0    [see, mrblanc, revealing, mystery, says, ranso...  \n",
       "1    [see, mrblanc, revealing, mystery, says, ranso...  \n",
       "2    [find, wondering, marta, dealt, inheritance, p...  \n",
       "3    [find, wondering, marta, dealt, inheritance, p...  \n",
       "4    [find, wondering, marta, dealt, inheritance, p...  \n",
       "..                                                 ...  \n",
       "122                                          [removed]  \n",
       "123  [immediately, sold, marta, realized, mother, w...  \n",
       "124  [immediately, sold, marta, realized, mother, w...  \n",
       "125  [question, mind, shown, one, scene, marthas, s...  \n",
       "126  [question, mind, shown, one, scene, marthas, s...  \n",
       "\n",
       "[124 rows x 10 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knivesout_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5196ca80",
   "metadata": {},
   "source": [
    "# \"r/Anne\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a3e48683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the folder containing the Harry Potter pickle files\n",
    "folder_path = r'C:\\Users\\josie\\Downloads\\Josie\\Anne'\n",
    "\n",
    "# List all the pickle files that the folder contains\n",
    "pickle_files = [file for file in os.listdir(folder_path) if file.startswith('subreddit_Anne')]\n",
    "\n",
    "# Initialize empty dictionary to store loaded data\n",
    "anne_data = {}\n",
    "\n",
    "# Load each pickle file and store its contents in the dictionary\n",
    "for file_name in pickle_files:\n",
    "    with open(os.path.join(folder_path, file_name), 'rb') as f:\n",
    "        knivesout_data[file_name] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "88c49322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries to store RS (Reddit submissions) and RC (Reddit comments) DataFrames\n",
    "rs_data = {}\n",
    "rc_data = {}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a Reddit submission file\n",
    "    if file_name.startswith(\"subreddit_Anne_RS\"):\n",
    "        # Load the RS DataFrame and store it in the dictionary with the corresponding date as the key\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rs_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "    \n",
    "    # Check if the file is a Reddit comment file\n",
    "    elif file_name.startswith(\"subreddit_Anne_RC\"):\n",
    "        # Load the RC DataFrame and store it in the dictionary with the corresponding date as the key\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rc_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "\n",
    "# Concatenate all the RS DataFrames into a single DataFrame\n",
    "anne_submissions = pd.concat(rs_data.values(), ignore_index=True)\n",
    "\n",
    "# Concatenate all the RC DataFrames into a single DataFrame\n",
    "anne_comments = pd.concat(rc_data.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7e6ecd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values in 'link_id' column start with 't3_': True\n"
     ]
    }
   ],
   "source": [
    "# Check if all values in 'link_id' column start with 't3_'\n",
    "all_values_start_with_t3 = anne_comments['link_id'].str.startswith('t3_').all()\n",
    "\n",
    "print(\"All values in 'link_id' column start with 't3_':\", all_values_start_with_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "04e00d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 't3_' prefix from the link_id column in the comments DataFrame\n",
    "anne_comments['link_id'] = anne_comments['link_id'].str.replace('t3_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d398fd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id_comment author_comment link_id   parent_id subreddit_comment  \\\n",
      "0    ds1hn4j    TorsionFree  7nfx88   t3_7nfx88           AnnePro   \n",
      "1    ds2sokd         quido3  7nfx88  t1_ds1hn4j           AnnePro   \n",
      "2    ds7gf2v        argon07  7nfx88  t1_ds1hn4j           AnnePro   \n",
      "3    ds7wzds        VexFlex  7nfx88   t3_7nfx88           AnnePro   \n",
      "4    ds1khcq      Thebatsem  7ng364   t3_7ng364           AnnePro   \n",
      "\n",
      "                                                body id_submission  \\\n",
      "0  You'd have to desolder all the switches to get...        7nfx88   \n",
      "1  Plastic? I'm pretty sure mine has a metal plat...        7nfx88   \n",
      "2            Dang I was hoping not to desolder...rip        7nfx88   \n",
      "3  Well if you have the patience to mask off all ...        7nfx88   \n",
      "4  I wouldn't bother about the warranty on these ...        7ng364   \n",
      "\n",
      "  author_submission subreddit_submission  \\\n",
      "0           argon07              AnnePro   \n",
      "1           argon07              AnnePro   \n",
      "2           argon07              AnnePro   \n",
      "3           argon07              AnnePro   \n",
      "4          xgdnekox              AnnePro   \n",
      "\n",
      "                                        title  \\\n",
      "0  Has anyone tried painting their backplate?   \n",
      "1  Has anyone tried painting their backplate?   \n",
      "2  Has anyone tried painting their backplate?   \n",
      "3  Has anyone tried painting their backplate?   \n",
      "4                Anne pro usb port broke off.   \n",
      "\n",
      "                                            selftext  \n",
      "0  I have a black anne pro rn and I never really ...  \n",
      "1  I have a black anne pro rn and I never really ...  \n",
      "2  I have a black anne pro rn and I never really ...  \n",
      "3  I have a black anne pro rn and I never really ...  \n",
      "4  Does obins have a warranty or should I look to...  \n"
     ]
    }
   ],
   "source": [
    "# Merge the submissions and comments DataFrames on the id and link_id columns\n",
    "merged_df = anne_comments.merge(anne_submissions, left_on='link_id', right_on='id', suffixes=('_comment', '_submission'))\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a9c8579d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id_comment author_comment   parent_id subreddit_comment  \\\n",
      "0    ds1hn4j    TorsionFree   t3_7nfx88           AnnePro   \n",
      "1    ds2sokd         quido3  t1_ds1hn4j           AnnePro   \n",
      "2    ds7gf2v        argon07  t1_ds1hn4j           AnnePro   \n",
      "3    ds7wzds        VexFlex   t3_7nfx88           AnnePro   \n",
      "4    ds1khcq      Thebatsem   t3_7ng364           AnnePro   \n",
      "\n",
      "                                                body author_submission  \\\n",
      "0  You'd have to desolder all the switches to get...           argon07   \n",
      "1  Plastic? I'm pretty sure mine has a metal plat...           argon07   \n",
      "2            Dang I was hoping not to desolder...rip           argon07   \n",
      "3  Well if you have the patience to mask off all ...           argon07   \n",
      "4  I wouldn't bother about the warranty on these ...          xgdnekox   \n",
      "\n",
      "  subreddit_submission                                       title  \\\n",
      "0              AnnePro  Has anyone tried painting their backplate?   \n",
      "1              AnnePro  Has anyone tried painting their backplate?   \n",
      "2              AnnePro  Has anyone tried painting their backplate?   \n",
      "3              AnnePro  Has anyone tried painting their backplate?   \n",
      "4              AnnePro                Anne pro usb port broke off.   \n",
      "\n",
      "                                            selftext  \n",
      "0  I have a black anne pro rn and I never really ...  \n",
      "1  I have a black anne pro rn and I never really ...  \n",
      "2  I have a black anne pro rn and I never really ...  \n",
      "3  I have a black anne pro rn and I never really ...  \n",
      "4  Does obins have a warranty or should I look to...  \n"
     ]
    }
   ],
   "source": [
    "# Remove the redundant columns\n",
    "anne_df = merged_df\n",
    "\n",
    "anne_df = anne_df.drop(['link_id','id_submission'], axis=1)\n",
    "\n",
    "print(anne_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "20ec9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "anne_df = anne_df[anne_df['body'] != '[deleted]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2fdb1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase 'body' column\n",
    "anne_df['body'] = anne_df['body'].str.lower()\n",
    "\n",
    "# Lowercase 'selftext' column\n",
    "anne_df['selftext'] = anne_df['selftext'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9f6576cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove punctuation from a string\n",
    "def remove_punctuation(text):\n",
    "    # Get the predefined set of punctuation characters\n",
    "    punctuation_set = set(string.punctuation)\n",
    "    # Use ''.join() to remove punctuation\n",
    "    return ''.join(char for char in text if char not in punctuation_set)\n",
    "\n",
    "# Remove punctuation from the relevant columns\n",
    "text_columns = ['body', 'selftext']\n",
    "anne_df[text_columns] = anne_df[text_columns].applymap(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c98fbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '\\n\\n' with a space in the 'body' and 'selftext' columns\n",
    "anne_df['body'] = anne_df['body'].str.replace('\\n\\n', ' ')\n",
    "anne_df['selftext'] = anne_df['selftext'].str.replace('\\n\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e350864a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to C:\\Users\\josie\\Downloads\\REDDIT_ANNE_DATA_CLEANED.txt\n"
     ]
    }
   ],
   "source": [
    "cleaned_file_path = r'C:\\Users\\josie\\Downloads\\REDDIT_ANNE_DATA_CLEANED.txt'\n",
    "knivesout_df.to_csv(cleaned_file_path, index=False, sep='\\t')\n",
    "\n",
    "print(f\"Cleaned data saved to {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ebb658",
   "metadata": {},
   "source": [
    "## Now save all relevant columns and groupings as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e13ba5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [i, have, a, black, anne, pro, rn, and, i, nev...\n",
      "1        [i, have, a, black, anne, pro, rn, and, i, nev...\n",
      "2        [i, have, a, black, anne, pro, rn, and, i, nev...\n",
      "3        [i, have, a, black, anne, pro, rn, and, i, nev...\n",
      "4        [does, obins, have, a, warranty, or, should, i...\n",
      "                               ...                        \n",
      "42551                                                   []\n",
      "42552                                                   []\n",
      "42553                                                   []\n",
      "42554                                            [deleted]\n",
      "42555                                                   []\n",
      "Name: selftext, Length: 41182, dtype: object\n",
      "0        [youd, have, to, desolder, all, the, switches,...\n",
      "1        [plastic, im, pretty, sure, mine, has, a, meta...\n",
      "2             [dang, i, was, hoping, not, to, desolderrip]\n",
      "3        [well, if, you, have, the, patience, to, mask,...\n",
      "4        [i, wouldnt, bother, about, the, warranty, on,...\n",
      "                               ...                        \n",
      "42551        [lmao, i, have, the, exact, same, combo, too]\n",
      "42552                               [good, taste, bruh, ]\n",
      "42553                                         [same, here]\n",
      "42554    [httpskbdfanscomcollections60layoutcaseproduct...\n",
      "42555                         [this, screams, wrist, pain]\n",
      "Name: body, Length: 41182, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the body and selftext columns\n",
    "anne_df['selftext'] = anne_df['selftext'].apply(word_tokenize)\n",
    "anne_df['body'] = anne_df['body'].apply(word_tokenize)\n",
    "\n",
    "# Print the updated 'body' column\n",
    "print(anne_df['selftext'])\n",
    "print(anne_df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f0940ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords from the tokenized 'body' column\n",
    "anne_df['body'] = anne_df['body'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
    "\n",
    "# Remove stopwords from the tokenized 'selftext' column\n",
    "anne_df['selftext'] = anne_df['selftext'].apply(lambda x: [word for word in x if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "523c3b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_comment</th>\n",
       "      <th>author_comment</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>subreddit_comment</th>\n",
       "      <th>body</th>\n",
       "      <th>author_submission</th>\n",
       "      <th>subreddit_submission</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ds1hn4j</td>\n",
       "      <td>TorsionFree</td>\n",
       "      <td>t3_7nfx88</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>[youd, desolder, switches, get, backplate, ord...</td>\n",
       "      <td>argon07</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>Has anyone tried painting their backplate?</td>\n",
       "      <td>[black, anne, pro, rn, never, really, use, rgb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ds2sokd</td>\n",
       "      <td>quido3</td>\n",
       "      <td>t1_ds1hn4j</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>[plastic, im, pretty, sure, mine, metal, plate...</td>\n",
       "      <td>argon07</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>Has anyone tried painting their backplate?</td>\n",
       "      <td>[black, anne, pro, rn, never, really, use, rgb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ds7gf2v</td>\n",
       "      <td>argon07</td>\n",
       "      <td>t1_ds1hn4j</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>[dang, hoping, desolderrip]</td>\n",
       "      <td>argon07</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>Has anyone tried painting their backplate?</td>\n",
       "      <td>[black, anne, pro, rn, never, really, use, rgb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ds7wzds</td>\n",
       "      <td>VexFlex</td>\n",
       "      <td>t3_7nfx88</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>[well, patience, mask, switches, im, pretty, s...</td>\n",
       "      <td>argon07</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>Has anyone tried painting their backplate?</td>\n",
       "      <td>[black, anne, pro, rn, never, really, use, rgb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ds1khcq</td>\n",
       "      <td>Thebatsem</td>\n",
       "      <td>t3_7ng364</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>[wouldnt, bother, warranty, products, would, s...</td>\n",
       "      <td>xgdnekox</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>Anne pro usb port broke off.</td>\n",
       "      <td>[obins, warranty, look, solder, new, one]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42551</th>\n",
       "      <td>fcojyqi</td>\n",
       "      <td>trukio</td>\n",
       "      <td>t3_ei2ux0</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>[lmao, exact, combo]</td>\n",
       "      <td>squanchymacsquanch</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>Nice combo (G305)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42552</th>\n",
       "      <td>fcok6or</td>\n",
       "      <td>squanchymacsquanch</td>\n",
       "      <td>t1_fcojyqi</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>[good, taste, bruh, ]</td>\n",
       "      <td>squanchymacsquanch</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>Nice combo (G305)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42553</th>\n",
       "      <td>fcold0g</td>\n",
       "      <td>zp3dd4</td>\n",
       "      <td>t1_fcojyqi</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>[]</td>\n",
       "      <td>squanchymacsquanch</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>Nice combo (G305)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42554</th>\n",
       "      <td>fcnrc6x</td>\n",
       "      <td>faddynuts</td>\n",
       "      <td>t3_ei0byk</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>[httpskbdfanscomcollections60layoutcaseproduct...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>Any Clear cases for the Anne Pro 2 yet? Perona...</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42555</th>\n",
       "      <td>fco59ic</td>\n",
       "      <td>OneArmCripple</td>\n",
       "      <td>t3_ei8dg9</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>[screams, wrist, pain]</td>\n",
       "      <td>sn4iI</td>\n",
       "      <td>AnnePro</td>\n",
       "      <td>if i didnt have a 60% i couldnt fit any keyb...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41182 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_comment      author_comment   parent_id subreddit_comment  \\\n",
       "0        ds1hn4j         TorsionFree   t3_7nfx88           AnnePro   \n",
       "1        ds2sokd              quido3  t1_ds1hn4j           AnnePro   \n",
       "2        ds7gf2v             argon07  t1_ds1hn4j           AnnePro   \n",
       "3        ds7wzds             VexFlex   t3_7nfx88           AnnePro   \n",
       "4        ds1khcq           Thebatsem   t3_7ng364           AnnePro   \n",
       "...          ...                 ...         ...               ...   \n",
       "42551    fcojyqi              trukio   t3_ei2ux0           AnnePro   \n",
       "42552    fcok6or  squanchymacsquanch  t1_fcojyqi           AnnePro   \n",
       "42553    fcold0g              zp3dd4  t1_fcojyqi           AnnePro   \n",
       "42554    fcnrc6x           faddynuts   t3_ei0byk           AnnePro   \n",
       "42555    fco59ic       OneArmCripple   t3_ei8dg9           AnnePro   \n",
       "\n",
       "                                                    body   author_submission  \\\n",
       "0      [youd, desolder, switches, get, backplate, ord...             argon07   \n",
       "1      [plastic, im, pretty, sure, mine, metal, plate...             argon07   \n",
       "2                            [dang, hoping, desolderrip]             argon07   \n",
       "3      [well, patience, mask, switches, im, pretty, s...             argon07   \n",
       "4      [wouldnt, bother, warranty, products, would, s...            xgdnekox   \n",
       "...                                                  ...                 ...   \n",
       "42551                               [lmao, exact, combo]  squanchymacsquanch   \n",
       "42552                             [good, taste, bruh, ]  squanchymacsquanch   \n",
       "42553                                                 []  squanchymacsquanch   \n",
       "42554  [httpskbdfanscomcollections60layoutcaseproduct...           [deleted]   \n",
       "42555                             [screams, wrist, pain]               sn4iI   \n",
       "\n",
       "      subreddit_submission                                              title  \\\n",
       "0                  AnnePro         Has anyone tried painting their backplate?   \n",
       "1                  AnnePro         Has anyone tried painting their backplate?   \n",
       "2                  AnnePro         Has anyone tried painting their backplate?   \n",
       "3                  AnnePro         Has anyone tried painting their backplate?   \n",
       "4                  AnnePro                       Anne pro usb port broke off.   \n",
       "...                    ...                                                ...   \n",
       "42551              AnnePro                                  Nice combo (G305)   \n",
       "42552              AnnePro                                  Nice combo (G305)   \n",
       "42553              AnnePro                                  Nice combo (G305)   \n",
       "42554              AnnePro  Any Clear cases for the Anne Pro 2 yet? Perona...   \n",
       "42555              AnnePro  if i didnt have a 60% i couldnt fit any keyb...   \n",
       "\n",
       "                                                selftext  \n",
       "0      [black, anne, pro, rn, never, really, use, rgb...  \n",
       "1      [black, anne, pro, rn, never, really, use, rgb...  \n",
       "2      [black, anne, pro, rn, never, really, use, rgb...  \n",
       "3      [black, anne, pro, rn, never, really, use, rgb...  \n",
       "4              [obins, warranty, look, solder, new, one]  \n",
       "...                                                  ...  \n",
       "42551                                                 []  \n",
       "42552                                                 []  \n",
       "42553                                                 []  \n",
       "42554                                          [deleted]  \n",
       "42555                                                 []  \n",
       "\n",
       "[41182 rows x 9 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anne_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb6124f",
   "metadata": {},
   "source": [
    "# \"r/The Last of Us\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "411a1117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the folder containing the pickle files\n",
    "folder_path = r'C:\\Users\\josie\\Downloads\\Josie\\TLOU'\n",
    "\n",
    "# List all the pickle files that the folder contains\n",
    "pickle_files = [file for file in os.listdir(folder_path) if file.endswith('.pickle')]\n",
    "\n",
    "# Initialize empty dictionary to store loaded data\n",
    "tlou_data = {}\n",
    "\n",
    "# Load each pickle file and store its contents in the dictionary\n",
    "for file_name in pickle_files:\n",
    "    with open(os.path.join(folder_path, file_name), 'rb') as f:\n",
    "        tlou_data[file_name] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "67780e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: subreddit_ThelastofusHBOseries_RC_2022-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RC_2022-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RC_2022-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RC_2022-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RC_2022-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RC_2022-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RC_2022-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RC_2022-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RC_2022-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RC_2022-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RC_2022-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RC_2022-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RS_2022-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'title', 'selftext', 'author', 'subreddit'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RS_2022-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'title', 'selftext', 'author', 'subreddit'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RS_2022-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'title', 'selftext', 'author', 'subreddit'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RS_2022-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'title', 'selftext', 'author', 'subreddit'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RS_2022-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'title', 'selftext', 'author', 'subreddit'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RS_2022-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'title', 'selftext', 'author', 'subreddit'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RS_2022-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'title', 'selftext', 'author', 'subreddit'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RS_2022-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'title', 'selftext', 'author', 'subreddit'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RS_2022-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'title', 'selftext', 'author', 'subreddit'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RS_2022-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'title', 'selftext', 'author', 'subreddit'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RS_2022-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'title', 'selftext', 'author', 'subreddit'], dtype='object')\n",
      "\n",
      "File: subreddit_ThelastofusHBOseries_RS_2022-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'title', 'selftext', 'author', 'subreddit'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RC_2022-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RC_2022-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RC_2022-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RC_2022-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RC_2022-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RC_2022-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RC_2022-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RC_2022-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RC_2022-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RC_2022-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RC_2022-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RC_2022-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RS_2022-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RS_2022-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RS_2022-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RS_2022-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RS_2022-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RS_2022-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RS_2022-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RS_2022-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RS_2022-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RS_2022-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RS_2022-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_thelastofus_RS_2022-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2014-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2014-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2014-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2014-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2014-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2014-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2014-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2014-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2014-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2014-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2014-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2014-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2022-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2022-02.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2022-03.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2022-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2022-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2022-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2022-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2022-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2022-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2022-11.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RC_2022-12.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'link_id', 'parent_id', 'subreddit', 'body'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RS_2022-01.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'title', 'selftext', 'author', 'subreddit'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RS_2022-04.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RS_2022-05.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RS_2022-06.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RS_2022-07.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RS_2022-08.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RS_2022-09.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n",
      "File: subreddit_TLOU_RS_2022-10.pickle\n",
      "Data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Keys: Index(['id', 'author', 'subreddit', 'title', 'selftext'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each pickle file and inspect its contents\n",
    "for file_name, data in tlou_data.items():\n",
    "    print(f\"File: {file_name}\")\n",
    "    print(f\"Data type: {type(data)}\")\n",
    "    print(f\"Keys: {data.keys()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b09564a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize empty dictionaries to store RS (Reddit submissions) and RC (Reddit comments) DataFrames\n",
    "rs_data = {}\n",
    "rc_data = {}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a Reddit submission file\n",
    "    if file_name.startswith(\"subreddit_TLOU_RS\"):\n",
    "        # Load the RS DataFrame and store it in the dictionary with the corresponding date as the key\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rs_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "    \n",
    "    # Check if the file is a Reddit comment file\n",
    "    elif file_name.startswith(\"subreddit_TLOU_RC\"):\n",
    "        # Load the RC DataFrame and store it in the dictionary with the corresponding date as the key\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rc_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "        \n",
    "    elif file_name.startswith(\"subreddit_thelastofus_RS\"):\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rs_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "        \n",
    "    elif file_name.startswith(\"subreddit_thelastofus_RC\"):\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rc_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "        \n",
    "    elif file_name.startswith(\"subreddit_ThelastofusHBOseries_RS\"):\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rs_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "        \n",
    "    elif file_name.startswith(\"subreddit_ThelastofusHBOseries_RC\"):\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rc_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "\n",
    "# Concatenate all the RS DataFrames into a single DataFrame\n",
    "tlou_submissions = pd.concat(rs_data.values(), ignore_index=True)\n",
    "\n",
    "# Concatenate all the RC DataFrames into a single DataFrame\n",
    "tlou_comments = pd.concat(rc_data.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8d9cb009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     link_id cleaned_link_id\n",
      "0  t3_rsq1a0          rsq1a0\n",
      "1  t3_rsq1a0          rsq1a0\n",
      "2  t3_rsq1a0          rsq1a0\n",
      "3  t3_hiae2t          hiae2t\n",
      "4  t3_hiae2t          hiae2t\n",
      "  id_comment     author_comment    link_id   parent_id subreddit_comment  \\\n",
      "0    i2x2syl           Aucielis  t3_tt02oa  t1_i2wyf8e       thelastofus   \n",
      "1    i2x4mhn  AbstractBettaFish  t3_tt02oa  t1_i2x16n2       thelastofus   \n",
      "2    i2x5fi6     awakenedforces  t3_tt02oa   t3_tt02oa       thelastofus   \n",
      "3    i2x6wiu     StreetMedic380  t3_tt02oa   t3_tt02oa       thelastofus   \n",
      "4    i2xah3o          Glitchy13  t3_tt02oa   t3_tt02oa       thelastofus   \n",
      "\n",
      "                                                body cleaned_link_id  \\\n",
      "0  Yeah, exactly. I think it's partly that for me...          tt02oa   \n",
      "1  The dumbest part is that he literally has an E...          tt02oa   \n",
      "2  makes me wonder if we all even played the same...          tt02oa   \n",
      "3  No character development and story issues?\\n\\n...          tt02oa   \n",
      "4                That guys sentence has bad pacing.          tt02oa   \n",
      "\n",
      "  id_submission                                           title selftext  \\\n",
      "0        tt02oa  Ive never seen such mixed opinions on a game.            \n",
      "1        tt02oa  Ive never seen such mixed opinions on a game.            \n",
      "2        tt02oa  Ive never seen such mixed opinions on a game.            \n",
      "3        tt02oa  Ive never seen such mixed opinions on a game.            \n",
      "4        tt02oa  Ive never seen such mixed opinions on a game.            \n",
      "\n",
      "    author_submission subreddit_submission  \n",
      "0  soggy_slippinjimmy          thelastofus  \n",
      "1  soggy_slippinjimmy          thelastofus  \n",
      "2  soggy_slippinjimmy          thelastofus  \n",
      "3  soggy_slippinjimmy          thelastofus  \n",
      "4  soggy_slippinjimmy          thelastofus  \n"
     ]
    }
   ],
   "source": [
    "# Remove the 't3_' prefix from every row in the link_id column\n",
    "tlou_comments['cleaned_link_id'] = tlou_comments['link_id'].str.replace('t3_', '', regex=False)\n",
    "\n",
    "# Display the first few rows to verify the prefix has been removed\n",
    "print(tlou_comments[['link_id', 'cleaned_link_id']].head())\n",
    "\n",
    "# Merge the DataFrames using the cleaned_link_id column and id column\n",
    "tlou_df = pd.merge(tlou_comments, tlou_submissions, left_on='cleaned_link_id', right_on='id', how='inner', suffixes=('_comment', '_submission'))\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(tlou_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "48529e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id_comment     author_comment subreddit_comment  \\\n",
      "0    i2x2syl           Aucielis       thelastofus   \n",
      "1    i2x4mhn  AbstractBettaFish       thelastofus   \n",
      "2    i2x5fi6     awakenedforces       thelastofus   \n",
      "3    i2x6wiu     StreetMedic380       thelastofus   \n",
      "4    i2xah3o          Glitchy13       thelastofus   \n",
      "\n",
      "                                                body id_submission  \\\n",
      "0  Yeah, exactly. I think it's partly that for me...        tt02oa   \n",
      "1  The dumbest part is that he literally has an E...        tt02oa   \n",
      "2  makes me wonder if we all even played the same...        tt02oa   \n",
      "3  No character development and story issues?\\n\\n...        tt02oa   \n",
      "4                That guys sentence has bad pacing.        tt02oa   \n",
      "\n",
      "                                            title selftext  \\\n",
      "0  Ive never seen such mixed opinions on a game.            \n",
      "1  Ive never seen such mixed opinions on a game.            \n",
      "2  Ive never seen such mixed opinions on a game.            \n",
      "3  Ive never seen such mixed opinions on a game.            \n",
      "4  Ive never seen such mixed opinions on a game.            \n",
      "\n",
      "    author_submission subreddit_submission  \n",
      "0  soggy_slippinjimmy          thelastofus  \n",
      "1  soggy_slippinjimmy          thelastofus  \n",
      "2  soggy_slippinjimmy          thelastofus  \n",
      "3  soggy_slippinjimmy          thelastofus  \n",
      "4  soggy_slippinjimmy          thelastofus  \n"
     ]
    }
   ],
   "source": [
    "#'cleaned_link_id' appears twice in the DataFrame\n",
    "tlou_df.drop(labels=['cleaned_link_id'], axis=1, inplace=True)\n",
    "tlou_df.drop(columns=['link_id', 'parent_id'], inplace=True)\n",
    "\n",
    "print(tlou_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c75c4a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with '[deleted]' in the 'body' column\n",
    "tlou_df = tlou_df[tlou_df['body'] != '[deleted]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "21209a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase 'body' column\n",
    "tlou_df['body'] = tlou_df['body'].str.lower()\n",
    "\n",
    "# Lowercase 'selftext' column\n",
    "tlou_df['selftext'] = tlou_df['selftext'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a5609c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Define a function to remove punctuation from a string\n",
    "def remove_punctuation(text):\n",
    "    # Get the predefined set of punctuation characters\n",
    "    punctuation_set = set(string.punctuation)\n",
    "    # Use ''.join() to remove punctuation\n",
    "    return ''.join(char for char in text if char not in punctuation_set)\n",
    "\n",
    "# Remove punctuation from the relevant columns\n",
    "text_columns = ['body', 'selftext']\n",
    "tlou_df[text_columns] = tlou_df[text_columns].applymap(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2fb53060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '\\n\\n' with a space in the 'body' and 'selftext' columns\n",
    "tlou_df['body'] = tlou_df['body'].str.replace('\\n\\n', ' ')\n",
    "tlou_df['selftext'] = tlou_df['selftext'].str.replace('\\n\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "eebaf523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to C:\\Users\\josie\\Downloads\\REDDIT_TLOU_DATA_CLEANED.txt\n"
     ]
    }
   ],
   "source": [
    "cleaned_file_path = r'C:\\Users\\josie\\Downloads\\REDDIT_TLOU_DATA_CLEANED.txt'\n",
    "tlou_df.to_csv(cleaned_file_path, index=False, sep='\\t')\n",
    "\n",
    "print(f\"Cleaned data saved to {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0fe63e",
   "metadata": {},
   "source": [
    "## Now save all columns and groupings accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3dd35c",
   "metadata": {},
   "source": [
    "# Breaking Bad Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "163ddc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the folder containing the pickle files\n",
    "folder_path = r'C:\\Users\\josie\\Downloads\\Josie\\BreakingBad'\n",
    "\n",
    "# List all the pickle files that the folder contains\n",
    "pickle_files = [file for file in os.listdir(folder_path) if file.endswith('.pickle')]\n",
    "\n",
    "# Initialize empty dictionary to store loaded data\n",
    "breakingbad_data = {}\n",
    "\n",
    "# Load each pickle file and store its contents in the dictionary\n",
    "for file_name in pickle_files:\n",
    "    with open(os.path.join(folder_path, file_name), 'rb') as f:\n",
    "        breakingbad_data[file_name] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2a443f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize empty dictionaries to store RS (Reddit submissions) and RC (Reddit comments) DataFrames\n",
    "rs_data = {}\n",
    "rc_data = {}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a Reddit submission file\n",
    "    if file_name.startswith(\"subreddit_breakingbad_RS\"):\n",
    "        # Load the RS DataFrame and store it in the dictionary with the corresponding date as the key\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rs_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "    \n",
    "    # Check if the file is a Reddit comment file\n",
    "    elif file_name.startswith(\"subreddit_breakingbad_RC\"):\n",
    "        # Load the RC DataFrame and store it in the dictionary with the corresponding date as the key\n",
    "        date = file_name.split(\"_\")[-1].split(\".\")[0]\n",
    "        rc_data[date] = pd.read_pickle(os.path.join(folder_path, file_name))\n",
    "\n",
    "# Concatenate all the RS DataFrames into a single DataFrame\n",
    "breakingbad_submissions = pd.concat(rs_data.values(), ignore_index=True)\n",
    "\n",
    "# Concatenate all the RC DataFrames into a single DataFrame\n",
    "breakingbad_comments = pd.concat(rc_data.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0534240b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    link_id cleaned_link_id\n",
      "0  t3_bges0           bges0\n",
      "1  t3_bges0           bges0\n",
      "2  t3_bges0           bges0\n",
      "3  t3_bges0           bges0\n",
      "4  t3_bges0           bges0\n",
      "  id_comment     author_comment   link_id   parent_id subreddit_comment  \\\n",
      "0    c0mnh22          [deleted]  t3_bges0    t3_bges0       breakingbad   \n",
      "1    c0mnut2        PopeAdolph2  t3_bges0    t3_bges0       breakingbad   \n",
      "2    c0mo174        Jack_Bandit  t3_bges0  t1_c0mnut2       breakingbad   \n",
      "3    c0mo93h  lkjhgfdsasdfghjkl  t3_bges0  t1_c0mnut2       breakingbad   \n",
      "4    c0mojz8        RyanOnymous  t3_bges0    t3_bges0       breakingbad   \n",
      "\n",
      "                                                body cleaned_link_id  \\\n",
      "0     Well shiite. I was about to make one of these.           bges0   \n",
      "1  great overall, but could have done without see...           bges0   \n",
      "2  I agree with everything except the crawling sc...           bges0   \n",
      "3  The auditorium scene showed that Walt was losi...           bges0   \n",
      "4  I'm re-watching the last few episodes of S2 in...           bges0   \n",
      "\n",
      "  id_submission author_submission                        title  \\\n",
      "0         bges0            coopnl  Breaking Bad subreddit!! :)   \n",
      "1         bges0            coopnl  Breaking Bad subreddit!! :)   \n",
      "2         bges0            coopnl  Breaking Bad subreddit!! :)   \n",
      "3         bges0            coopnl  Breaking Bad subreddit!! :)   \n",
      "4         bges0            coopnl  Breaking Bad subreddit!! :)   \n",
      "\n",
      "                                            selftext subreddit_submission  \n",
      "0  I figured as long as there could be a subreddi...          breakingbad  \n",
      "1  I figured as long as there could be a subreddi...          breakingbad  \n",
      "2  I figured as long as there could be a subreddi...          breakingbad  \n",
      "3  I figured as long as there could be a subreddi...          breakingbad  \n",
      "4  I figured as long as there could be a subreddi...          breakingbad  \n"
     ]
    }
   ],
   "source": [
    "# Remove the 't3_' prefix from every row in the link_id column\n",
    "breakingbad_comments['cleaned_link_id'] = breakingbad_comments['link_id'].str.replace('t3_', '', regex=False)\n",
    "\n",
    "# Display the first few rows to verify the prefix has been removed\n",
    "print(breakingbad_comments[['link_id', 'cleaned_link_id']].head())\n",
    "\n",
    "# Merge the DataFrames using the cleaned_link_id column and id column\n",
    "breakingbad_df = pd.merge(breakingbad_comments, breakingbad_submissions, left_on='cleaned_link_id', right_on='id', how='inner', suffixes=('_comment', '_submission'))\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(breakingbad_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b46ec7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id_comment     author_comment subreddit_comment  \\\n",
      "0    c0mnh22          [deleted]       breakingbad   \n",
      "1    c0mnut2        PopeAdolph2       breakingbad   \n",
      "2    c0mo174        Jack_Bandit       breakingbad   \n",
      "3    c0mo93h  lkjhgfdsasdfghjkl       breakingbad   \n",
      "4    c0mojz8        RyanOnymous       breakingbad   \n",
      "\n",
      "                                                body id_submission  \\\n",
      "0     Well shiite. I was about to make one of these.         bges0   \n",
      "1  great overall, but could have done without see...         bges0   \n",
      "2  I agree with everything except the crawling sc...         bges0   \n",
      "3  The auditorium scene showed that Walt was losi...         bges0   \n",
      "4  I'm re-watching the last few episodes of S2 in...         bges0   \n",
      "\n",
      "  author_submission                        title  \\\n",
      "0            coopnl  Breaking Bad subreddit!! :)   \n",
      "1            coopnl  Breaking Bad subreddit!! :)   \n",
      "2            coopnl  Breaking Bad subreddit!! :)   \n",
      "3            coopnl  Breaking Bad subreddit!! :)   \n",
      "4            coopnl  Breaking Bad subreddit!! :)   \n",
      "\n",
      "                                            selftext subreddit_submission  \n",
      "0  I figured as long as there could be a subreddi...          breakingbad  \n",
      "1  I figured as long as there could be a subreddi...          breakingbad  \n",
      "2  I figured as long as there could be a subreddi...          breakingbad  \n",
      "3  I figured as long as there could be a subreddi...          breakingbad  \n",
      "4  I figured as long as there could be a subreddi...          breakingbad  \n"
     ]
    }
   ],
   "source": [
    "#'cleaned_link_id' appears twice in the DataFrame\n",
    "breakingbad_df.drop(labels=['cleaned_link_id'], axis=1, inplace=True)\n",
    "breakingbad_df.drop(columns=['link_id', 'parent_id'], inplace=True)\n",
    "\n",
    "print(breakingbad_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "39a640b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with '[deleted]' in the 'body' column\n",
    "breakingbad_df = breakingbad_df[breakingbad_df['body'] != '[deleted]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "83a8ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase 'body' column\n",
    "breakingbad_df['body'] = breakingbad_df['body'].str.lower()\n",
    "\n",
    "# Lowercase 'selftext' column\n",
    "breakingbad_df['selftext'] = breakingbad_df['selftext'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e7f3050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Define a function to remove punctuation from a string\n",
    "def remove_punctuation(text):\n",
    "    # Get the predefined set of punctuation characters\n",
    "    punctuation_set = set(string.punctuation)\n",
    "    # Use ''.join() to remove punctuation\n",
    "    return ''.join(char for char in text if char not in punctuation_set)\n",
    "\n",
    "# Remove punctuation from the relevant columns\n",
    "text_columns = ['body', 'selftext']\n",
    "breakingbad_df[text_columns] = breakingbad_df[text_columns].applymap(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a3349c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '\\n\\n' with a space in the 'body' and 'selftext' columns\n",
    "breakingbad_df['body'] = breakingbad_df['body'].str.replace('\\n\\n', ' ')\n",
    "breakingbad_df['selftext'] = breakingbad_df['selftext'].str.replace('\\n\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b8d2a4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to C:\\Users\\josie\\Downloads\\REDDIT_BREAKINGBAD_DATA_CLEANED.txt\n"
     ]
    }
   ],
   "source": [
    "cleaned_file_path = r'C:\\Users\\josie\\Downloads\\REDDIT_BREAKINGBAD_DATA_CLEANED.txt'\n",
    "breakingbad_df.to_csv(cleaned_file_path, index=False, sep='\\t')\n",
    "\n",
    "print(f\"Cleaned data saved to {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1fd16",
   "metadata": {},
   "source": [
    "## Now save all relevant columns and groupings accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e1172d",
   "metadata": {},
   "source": [
    "# Catcher in the Rye Reddit Data, from \"r/Literature\" and \"r/Books\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1765d998",
   "metadata": {},
   "source": [
    "This data was gathered through a scraper tool and so will be loaded into the terminal differently.\n",
    "\n",
    "First, I will load the entire folder containing all 18 Reddit threads pertaining to Catcher in the Rye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cce50ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           title  \\\n",
      "0  What did you think of the Catcher in the Rye?   \n",
      "1  What did you think of the Catcher in the Rye?   \n",
      "2  What did you think of the Catcher in the Rye?   \n",
      "3  What did you think of the Catcher in the Rye?   \n",
      "4  What did you think of the Catcher in the Rye?   \n",
      "\n",
      "                                            selftext  \\\n",
      "0  I just finished reading it. The part where he ...   \n",
      "1  I just finished reading it. The part where he ...   \n",
      "2  I just finished reading it. The part where he ...   \n",
      "3  I just finished reading it. The part where he ...   \n",
      "4  I just finished reading it. The part where he ...   \n",
      "\n",
      "                                                body parent_id  \n",
      "0  \"New Release:How to Read a Book by Monica Wood...      C_01  \n",
      "1  It's a classic for a reason. It uses an unreli...      C_01  \n",
      "2                                     Are you a bot?      C_01  \n",
      "3                                        Hahaha nope      C_01  \n",
      "4  There are two major things going on with the c...      C_01  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the submissions .csv file into a DataFrame\n",
    "catcher_df = pd.read_csv(r\"C:\\Users\\josie\\OneDrive\\Desktop\\Reddit\\Catcher_in_the_Rye\\Catcher_in_the_Rye_Data.csv\")\n",
    "\n",
    "# Display the first few rows of each DataFrame to confirm\n",
    "print(catcher_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a2421a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\josie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\josie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\josie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           title  \\\n",
      "0  What did you think of the Catcher in the Rye?   \n",
      "1  What did you think of the Catcher in the Rye?   \n",
      "2  What did you think of the Catcher in the Rye?   \n",
      "3  What did you think of the Catcher in the Rye?   \n",
      "4  What did you think of the Catcher in the Rye?   \n",
      "\n",
      "                                            selftext  \\\n",
      "0  finished reading  part mental hospital rehab n...   \n",
      "1  finished reading  part mental hospital rehab n...   \n",
      "2  finished reading  part mental hospital rehab n...   \n",
      "3  finished reading  part mental hospital rehab n...   \n",
      "4  finished reading  part mental hospital rehab n...   \n",
      "\n",
      "                                                body parent_id  \n",
      "0   new release  read book monica woodcheck thewe...      C_01  \n",
      "1  s classic reason  uses unreliable narrator eff...      C_01  \n",
      "2                                               bot       C_01  \n",
      "3                                        hahaha nope      C_01  \n",
      "4  two major things going character  first growin...      C_01  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK relevant files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Replace slashes with spaces\n",
    "    text = text.replace('/', ' ')\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Join words back into a single string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the cleaning function to the 'selftext' and 'body' columns\n",
    "catcher_df['selftext'] = catcher_df['selftext'].astype(str).apply(clean_text)\n",
    "catcher_df['body'] = catcher_df['body'].astype(str).apply(clean_text)\n",
    "\n",
    "# Define a function to remove punctuation from a string\n",
    "def remove_punctuation(text):\n",
    "    # Get the predefined set of punctuation characters\n",
    "    punctuation_set = set(string.punctuation)\n",
    "    # Use ''.join() to remove punctuation\n",
    "    return ''.join(char for char in text if char not in punctuation_set)\n",
    "\n",
    "# Remove punctuation from the relevant columns\n",
    "text_columns = ['body', 'selftext']\n",
    "catcher_df[text_columns] = catcher_df[text_columns].applymap(remove_punctuation)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "print(catcher_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1ca23e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to C:\\Users\\josie\\Downloads\\catcher_df_CLEANED_FULL_REDDIT.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = r'C:\\Users\\josie\\Downloads\\catcher_df_CLEANED_FULL_REDDIT.txt'\n",
    "catcher_df.to_csv(output_file_path, index=False, sep='\\t', header=True)\n",
    "\n",
    "print(f\"DataFrame saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e9566984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'body' column saved to C:\\Users\\josie\\Downloads\\catcher_df_CLEANED_BODY_REDDIT.txt\n"
     ]
    }
   ],
   "source": [
    "output_file_path = r'C:\\Users\\josie\\Downloads\\catcher_df_CLEANED_BODY_REDDIT.txt'\n",
    "catcher_df['body'].to_csv(output_file_path, index=False, header=False)\n",
    "\n",
    "print(f\"'body' column saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0879b4ec",
   "metadata": {},
   "source": [
    "## Now save all relevant columns and groupings accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "016192a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "catcher_df['body'] = catcher_df['body'].apply(word_tokenize)\n",
    "catcher_df['selftext'] = catcher_df['selftext'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f7baf",
   "metadata": {},
   "source": [
    "The data is now ready for analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "28790630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>body</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What did you think of the Catcher in the Rye?</td>\n",
       "      <td>[finished, reading, part, mental, hospital, re...</td>\n",
       "      <td>[new, release, read, book, monica, woodcheck, ...</td>\n",
       "      <td>C_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What did you think of the Catcher in the Rye?</td>\n",
       "      <td>[finished, reading, part, mental, hospital, re...</td>\n",
       "      <td>[s, classic, reason, uses, unreliable, narrato...</td>\n",
       "      <td>C_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What did you think of the Catcher in the Rye?</td>\n",
       "      <td>[finished, reading, part, mental, hospital, re...</td>\n",
       "      <td>[bot]</td>\n",
       "      <td>C_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What did you think of the Catcher in the Rye?</td>\n",
       "      <td>[finished, reading, part, mental, hospital, re...</td>\n",
       "      <td>[hahaha, nope]</td>\n",
       "      <td>C_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What did you think of the Catcher in the Rye?</td>\n",
       "      <td>[finished, reading, part, mental, hospital, re...</td>\n",
       "      <td>[two, major, things, going, character, first, ...</td>\n",
       "      <td>C_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>Am I supposed to hate Holden Caulfield?</td>\n",
       "      <td>[started, reading, , catcher, rye, , school,...</td>\n",
       "      <td>[know, insufferable, even, reading, age]</td>\n",
       "      <td>C_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>Am I supposed to hate Holden Caulfield?</td>\n",
       "      <td>[started, reading, , catcher, rye, , school,...</td>\n",
       "      <td>[ve, always, thought, re, supposed, look, hold...</td>\n",
       "      <td>C_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>Am I supposed to hate Holden Caulfield?</td>\n",
       "      <td>[started, reading, , catcher, rye, , school,...</td>\n",
       "      <td>[writer, , intend, control, reaction, ion, wo...</td>\n",
       "      <td>C_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>Am I supposed to hate Holden Caulfield?</td>\n",
       "      <td>[started, reading, , catcher, rye, , school,...</td>\n",
       "      <td>[warning, example, step, mother, 83, read, las...</td>\n",
       "      <td>C_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>Am I supposed to hate Holden Caulfield?</td>\n",
       "      <td>[started, reading, , catcher, rye, , school,...</td>\n",
       "      <td>[someday, , like, find, without, needing, rer...</td>\n",
       "      <td>C_18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2495 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  \\\n",
       "0     What did you think of the Catcher in the Rye?   \n",
       "1     What did you think of the Catcher in the Rye?   \n",
       "2     What did you think of the Catcher in the Rye?   \n",
       "3     What did you think of the Catcher in the Rye?   \n",
       "4     What did you think of the Catcher in the Rye?   \n",
       "...                                             ...   \n",
       "2490        Am I supposed to hate Holden Caulfield?   \n",
       "2491        Am I supposed to hate Holden Caulfield?   \n",
       "2492        Am I supposed to hate Holden Caulfield?   \n",
       "2493        Am I supposed to hate Holden Caulfield?   \n",
       "2494        Am I supposed to hate Holden Caulfield?   \n",
       "\n",
       "                                               selftext  \\\n",
       "0     [finished, reading, part, mental, hospital, re...   \n",
       "1     [finished, reading, part, mental, hospital, re...   \n",
       "2     [finished, reading, part, mental, hospital, re...   \n",
       "3     [finished, reading, part, mental, hospital, re...   \n",
       "4     [finished, reading, part, mental, hospital, re...   \n",
       "...                                                 ...   \n",
       "2490  [started, reading, , catcher, rye, , school,...   \n",
       "2491  [started, reading, , catcher, rye, , school,...   \n",
       "2492  [started, reading, , catcher, rye, , school,...   \n",
       "2493  [started, reading, , catcher, rye, , school,...   \n",
       "2494  [started, reading, , catcher, rye, , school,...   \n",
       "\n",
       "                                                   body parent_id  \n",
       "0     [new, release, read, book, monica, woodcheck, ...      C_01  \n",
       "1     [s, classic, reason, uses, unreliable, narrato...      C_01  \n",
       "2                                                 [bot]      C_01  \n",
       "3                                        [hahaha, nope]      C_01  \n",
       "4     [two, major, things, going, character, first, ...      C_01  \n",
       "...                                                 ...       ...  \n",
       "2490           [know, insufferable, even, reading, age]      C_18  \n",
       "2491  [ve, always, thought, re, supposed, look, hold...      C_18  \n",
       "2492  [writer, , intend, control, reaction, ion, wo...      C_18  \n",
       "2493  [warning, example, step, mother, 83, read, las...      C_18  \n",
       "2494  [someday, , like, find, without, needing, rer...      C_18  \n",
       "\n",
       "[2495 rows x 4 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catcher_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
